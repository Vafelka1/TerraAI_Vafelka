{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c574e8d4-8c27-4d93-890d-f7c1625b24be",
   "metadata": {},
   "source": [
    "Скачиваем датасет с Я.диска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aec632e-fc6b-4d91-ad07-ea5068805988",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:22:50.158883Z",
     "iopub.status.busy": "2024-04-10T17:22:50.158058Z",
     "iopub.status.idle": "2024-04-10T17:24:36.441117Z",
     "shell.execute_reply": "2024-04-10T17:24:36.440410Z",
     "shell.execute_reply.started": "2024-04-10T17:22:50.158845Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pragma dataset init Renopaty --size 4Gb\n",
    "\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "\n",
    "base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?'\n",
    "public_key = 'https://disk.yandex.ru/d/uHaTRuAlbdbpdQ'\n",
    "\n",
    "final_url = base_url + urlencode(dict(public_key=public_key))\n",
    "response = requests.get(final_url)\n",
    "download_url = response.json()['href']\n",
    "response = requests.get(download_url)\n",
    "\n",
    "dist_path = '/home/jupyter/mnt/datasets/Renopaty/'\n",
    "zipfile = ZipFile(BytesIO(response.content))\n",
    "zipfile.extractall(path=dist_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07230d89-fb47-4f8e-8e36-ed0380ea3c89",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3293de0-0c2d-47da-bf97-4086a3ca2a64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T19:47:29.524059Z",
     "iopub.status.busy": "2024-04-10T19:47:29.523279Z",
     "iopub.status.idle": "2024-04-10T19:47:45.576738Z",
     "shell.execute_reply": "2024-04-10T19:47:45.575880Z",
     "shell.execute_reply.started": "2024-04-10T19:47:29.524018Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 19:47:32.040252: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-10 19:47:33.494034: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-10 19:47:37.184622: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Input, Dense, Flatten, Lambda, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import applications, losses, optimizers, metrics, Model\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "066e6c9c-5a04-427f-acf1-7432e3bd8489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T19:47:45.578973Z",
     "iopub.status.busy": "2024-04-10T19:47:45.578043Z",
     "iopub.status.idle": "2024-04-10T19:47:45.616095Z",
     "shell.execute_reply": "2024-04-10T19:47:45.615251Z",
     "shell.execute_reply.started": "2024-04-10T19:47:45.578936Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_paths = '/home/jupyter/datasphere/datasets/Renopaty/Test'\n",
    "train_paths = '/home/jupyter/datasphere/datasets/Renopaty/Train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d459ef5e-2b6b-4e85-aee3-84c3d3c3d429",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T19:47:45.618612Z",
     "iopub.status.busy": "2024-04-10T19:47:45.618052Z",
     "iopub.status.idle": "2024-04-10T19:47:45.746813Z",
     "shell.execute_reply": "2024-04-10T19:47:45.745892Z",
     "shell.execute_reply.started": "2024-04-10T19:47:45.618582Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6408 images for training in class 0\n",
      "712  images for testing in class 0\n",
      "2532 images for training in class 1\n",
      "281  images for testing in class 1\n",
      "3502 images for training in class 2\n",
      "389  images for testing in class 2\n",
      "2879 images for training in class 3\n",
      "319  images for testing in class 3\n",
      "2709 images for training in class 4\n",
      "300  images for testing in class 4\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  test_paths = f'/home/jupyter/datasphere/datasets/Renopaty/Test/{i}'\n",
    "  train_paths = f'/home/jupyter/datasphere/datasets/Renopaty/Train/{i}'\n",
    "  print(len(os.listdir(train_paths)), f'images for training in class {i}')\n",
    "  print(len(os.listdir(test_paths)), f' images for testing in class {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbcf7f18-a775-490a-b504-d186d6a4db35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T19:47:45.748929Z",
     "iopub.status.busy": "2024-04-10T19:47:45.748342Z",
     "iopub.status.idle": "2024-04-10T19:47:45.759129Z",
     "shell.execute_reply": "2024-04-10T19:47:45.758381Z",
     "shell.execute_reply.started": "2024-04-10T19:47:45.748898Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/jupyter/datasphere/datasets/Renopaty/Train'\n",
    "batch_size = 48 \n",
    "image_size = (380,380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "964c88a4-c067-4e1b-9da3-1c1764a36de9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T19:47:45.760922Z",
     "iopub.status.busy": "2024-04-10T19:47:45.760112Z",
     "iopub.status.idle": "2024-04-10T19:47:51.077627Z",
     "shell.execute_reply": "2024-04-10T19:47:51.076719Z",
     "shell.execute_reply.started": "2024-04-10T19:47:45.760877Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18030 files belonging to 5 classes.\n",
      "Using 14424 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 19:47:47.531229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31136 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8c:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18030 files belonging to 5 classes.\n",
      "Using 3606 files for validation.\n",
      "['0', '1', '2', '3', '4']\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,                  # Путь к изображениям\n",
    "  validation_split = 0.2,    # Устанавливаем разделение на обучающую и проверочную выборки (10%)\n",
    "  subset = \"training\",       # Помечаем, что выборка обучающая (90%)\n",
    "  seed = 123,                # Дополнительное случайное начальное число для перетасовки и преобразований\n",
    "  image_size = image_size,   # Размер изображений, который был задан ранее\n",
    "  batch_size = batch_size)   # Размер батча, который был задан ранее\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,                  # Путь к изображениям\n",
    "  validation_split = 0.2,    # Устанавливаем разделение на обучающую и проверочную выборки (10%)\n",
    "  subset = \"validation\",     # Помечаем, что выборка проверочная (10%)\n",
    "  seed = 123,                # Дополнительное случайное начальное число для перетасовки и преобразований\n",
    "  image_size = image_size,   # Размер изображений, который был задан ранее\n",
    "  batch_size = batch_size)   # Размер батча, который был задан ранее\n",
    "  \n",
    "                             # Определяем имена классов:\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0cda37a-1925-419b-a8f8-5f0f1655cd47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T19:47:51.079544Z",
     "iopub.status.busy": "2024-04-10T19:47:51.078702Z",
     "iopub.status.idle": "2024-04-10T19:47:51.108182Z",
     "shell.execute_reply": "2024-04-10T19:47:51.107327Z",
     "shell.execute_reply.started": "2024-04-10T19:47:51.079496Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 380, 380, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE) # Предварительная обучающая выборка\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)     # Предварительная тестовая выборка\n",
    "\n",
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc34ae8f-3228-460f-909f-94c26e748a90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T19:47:51.109956Z",
     "iopub.status.busy": "2024-04-10T19:47:51.109265Z",
     "iopub.status.idle": "2024-04-10T19:47:58.044051Z",
     "shell.execute_reply": "2024-04-10T19:47:58.043126Z",
     "shell.execute_reply.started": "2024-04-10T19:47:51.109911Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Resnet = tf.keras.applications.ResNet152V2(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(380, 380, 3),\n",
    ")\n",
    "\n",
    "Input = tf.keras.Input(shape=(380, 380, 3))\n",
    "x = preprocess_input(Input)\n",
    "x = Resnet(x,training=True)\n",
    "out_conv = tf.keras.layers.Conv2D(filters=5, kernel_size=1, strides=(1, 1), activation='selu', padding='same', name='out_conv')(x)\n",
    "gmp = tf.keras.layers.GlobalMaxPool2D()(out_conv)\n",
    "out = Flatten()(gmp)\n",
    "Resnet_model = Model(inputs=Input, outputs=[out], name='4Classes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cc5ccbf-9f4c-49a0-92f6-a373352858b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T19:47:58.047359Z",
     "iopub.status.busy": "2024-04-10T19:47:58.046816Z",
     "iopub.status.idle": "2024-04-10T19:47:58.106480Z",
     "shell.execute_reply": "2024-04-10T19:47:58.105688Z",
     "shell.execute_reply.started": "2024-04-10T19:47:58.047328Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"4Classes\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 380, 380, 3)]     0         \n",
      "                                                                 \n",
      " tf.math.truediv (TFOpLambda  (None, 380, 380, 3)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf.math.subtract (TFOpLambd  (None, 380, 380, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " resnet152v2 (Functional)    (None, 12, 12, 2048)      58331648  \n",
      "                                                                 \n",
      " out_conv (Conv2D)           (None, 12, 12, 5)         10245     \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 5)                0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,341,893\n",
      "Trainable params: 58,198,149\n",
      "Non-trainable params: 143,744\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e52de1b-a3cf-455d-a11e-e3a336f80b9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T19:47:58.108567Z",
     "iopub.status.busy": "2024-04-10T19:47:58.107916Z",
     "iopub.status.idle": "2024-04-10T19:47:58.124854Z",
     "shell.execute_reply": "2024-04-10T19:47:58.123909Z",
     "shell.execute_reply.started": "2024-04-10T19:47:58.108535Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_graph(train_acc, val_acc, train_loss, val_loss):\n",
    "  '''\n",
    "  Функция выведет на экран графики точности и ошибки на проверочной и обучающей выборках.\n",
    "  '''\n",
    "  sns.set(style='darkgrid', palette='dark') \n",
    "  plt.figure(figsize=(16, 10))\n",
    "  plt.subplot(2, 2, 1)\n",
    "  plt.title('Точность', fontweight='bold')\n",
    "  plt.plot(train_acc, label='Точность на обучащей выборке')\n",
    "  plt.plot(val_acc, label='Точность на проверочной выборке')\n",
    "  plt.xlabel('Эпоха обучения')\n",
    "  plt.ylabel('Доля верных ответов')\n",
    "  plt.legend()\n",
    "\n",
    "  plt.subplot(2, 2, 2)\n",
    "  plt.title('Ошибка', fontweight='bold')\n",
    "  plt.plot(train_loss, label='Ошибка на обучающей выборке')\n",
    "  plt.plot(val_loss, label='Ошибка на проверочной выборке')\n",
    "  plt.xlabel('Эпоха обучения')\n",
    "  plt.ylabel('Ошибка')\n",
    "  plt.legend()\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "903374e1-b206-4a3d-babe-ded94a53e1c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T19:47:58.127083Z",
     "iopub.status.busy": "2024-04-10T19:47:58.126141Z",
     "iopub.status.idle": "2024-04-10T19:47:58.161276Z",
     "shell.execute_reply": "2024-04-10T19:47:58.160268Z",
     "shell.execute_reply.started": "2024-04-10T19:47:58.127039Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001                                                                        \n",
    "# Компилируем модель:\n",
    "Resnet_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),  # Оптимизатор Adam c заданным ранее шагом обучения\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  # Ошибка SparseCategoricalCrossentropy\n",
    "              metrics=['accuracy'])                                                  # Метрика Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f56ce1b4-68ad-4a45-a20f-0241e801d452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T19:47:58.163190Z",
     "iopub.status.busy": "2024-04-10T19:47:58.162450Z",
     "iopub.status.idle": "2024-04-10T19:47:58.186081Z",
     "shell.execute_reply": "2024-04-10T19:47:58.185235Z",
     "shell.execute_reply.started": "2024-04-10T19:47:58.163148Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5fb2c5e-68e9-48f6-8f41-f207ae4c03ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T19:47:58.187913Z",
     "iopub.status.busy": "2024-04-10T19:47:58.187255Z",
     "iopub.status.idle": "2024-04-10T19:47:58.426142Z",
     "shell.execute_reply": "2024-04-10T19:47:58.425134Z",
     "shell.execute_reply.started": "2024-04-10T19:47:58.187871Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20581"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c793cf-2d84-45b8-af93-b28530b3b2a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T19:47:58.428162Z",
     "iopub.status.busy": "2024-04-10T19:47:58.427381Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 19:47:58.491236: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [14424]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2024-04-10 19:47:58.491852: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [14424]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 19:48:39.030721: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2024-04-10 19:48:42.641882: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f4c5b851c40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-10 19:48:42.641929: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-04-10 19:48:42.793146: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-10 19:48:43.764722: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - ETA: 0s - loss: 1.4444 - accuracy: 0.4461"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 19:54:09.098013: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [3606]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2024-04-10 19:54:09.098414: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [3606]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.18135, saving model to /home/jupyter/datasphere/project/MobileNetV1.h5\n",
      "301/301 [==============================] - 406s 1s/step - loss: 1.4444 - accuracy: 0.4461 - val_loss: 1.1814 - val_accuracy: 0.5133 - lr: 1.0000e-04\n",
      "Epoch 2/15\n",
      "301/301 [==============================] - ETA: 0s - loss: 1.0965 - accuracy: 0.5484\n",
      "Epoch 2: val_loss improved from 1.18135 to 1.04591, saving model to /home/jupyter/datasphere/project/MobileNetV1.h5\n",
      "301/301 [==============================] - 295s 980ms/step - loss: 1.0965 - accuracy: 0.5484 - val_loss: 1.0459 - val_accuracy: 0.5646 - lr: 1.0000e-04\n",
      "Epoch 3/15\n",
      "301/301 [==============================] - ETA: 0s - loss: 0.9300 - accuracy: 0.6177\n",
      "Epoch 3: val_loss improved from 1.04591 to 1.04223, saving model to /home/jupyter/datasphere/project/MobileNetV1.h5\n",
      "301/301 [==============================] - 295s 981ms/step - loss: 0.9300 - accuracy: 0.6177 - val_loss: 1.0422 - val_accuracy: 0.5790 - lr: 1.0000e-04\n",
      "Epoch 4/15\n",
      "301/301 [==============================] - ETA: 0s - loss: 0.7841 - accuracy: 0.6850\n",
      "Epoch 4: val_loss did not improve from 1.04223\n",
      "301/301 [==============================] - 289s 961ms/step - loss: 0.7841 - accuracy: 0.6850 - val_loss: 1.0557 - val_accuracy: 0.5713 - lr: 1.0000e-04\n",
      "Epoch 5/15\n",
      "301/301 [==============================] - ETA: 0s - loss: 0.6576 - accuracy: 0.7375\n",
      "Epoch 5: val_loss did not improve from 1.04223\n",
      "301/301 [==============================] - 290s 962ms/step - loss: 0.6576 - accuracy: 0.7375 - val_loss: 1.1098 - val_accuracy: 0.5599 - lr: 1.0000e-04\n",
      "Epoch 6/15\n",
      "301/301 [==============================] - ETA: 0s - loss: 0.5262 - accuracy: 0.7985\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 6.999999823165126e-05.\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.04223\n",
      "301/301 [==============================] - 290s 963ms/step - loss: 0.5262 - accuracy: 0.7985 - val_loss: 1.2405 - val_accuracy: 0.5469 - lr: 1.0000e-04\n",
      "Epoch 7/15\n",
      " 57/301 [====>.........................] - ETA: 3:35 - loss: 0.4552 - accuracy: 0.8249"
     ]
    }
   ],
   "source": [
    "epochs = 15    \n",
    "\n",
    "#Задаем коллбеки  \n",
    "history_path = '/home/jupyter/datasphere/project/model_history_log2.csv'\n",
    "weights_path = '/home/jupyter/datasphere/project/MobileNetV1.h5'\n",
    "\n",
    "csv_logger = CSVLogger(history_path, append=True)\n",
    "# уменьшение lr\n",
    "reduceLROnPlateau = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=3, verbose=1)\n",
    "# сохранение весов\n",
    "model_checkpoint = ModelCheckpoint(weights_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "\n",
    "Retina_Resnet = Resnet_model.fit(train_ds,                 # Обучающая выборка\n",
    "                        epochs=epochs,            # Количество эпох обучения, заданное ранее\n",
    "                        validation_data=val_ds,\n",
    "                        callbacks=[csv_logger,\n",
    "                                   reduceLROnPlateau,\n",
    "                                   model_checkpoint])   # Проверочная выборка\n",
    "\n",
    "                                                    # После того, как пройдет обучение, выведем графики точности и ошибки:\n",
    "plot_graph(Retina_Resnet.history['accuracy'],\n",
    "           Retina_Resnet.history['val_accuracy'],\n",
    "           Retina_Resnet.history['loss'],\n",
    "           Retina_Resnet.history['val_loss'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0eaed272-de51-4039-a77f-9ea206ccdf78",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac9a179-14d4-463f-9e7e-c8d43871cd22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dir = '/home/jupyter/datasphere/datasets/Renopaty/Test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f06cf9-edd4-42f6-a555-459c9c001e1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  test_dir,                  # Путь к изображениям\n",
    "  validation_split = 0.9999,    # Устанавливаем разделение на обучающую и проверочную выборки (10%)\n",
    "  subset = \"training\",       # Помечаем, что выборка обучающая (90%)\n",
    "  seed = 123,                # Дополнительное случайное начальное число для перетасовки и преобразований\n",
    "  image_size = image_size,   # Размер изображений, который был задан ранее\n",
    "  batch_size = batch_size)   # Размер батча, который был задан ранее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72af090f-0931-44d3-86aa-6185b3b320cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)     # Предварительная тестовая выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094c83c1-6c41-4d09-be9f-ad293176a215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Проверка модели на тестовых картинках не участвовавших в обучении\n",
    "scores = Resnet_model.evaluate(val_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947870b1-4c1d-4c7d-b292-0edac35017ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
