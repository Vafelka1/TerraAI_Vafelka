{"cells":[{"cell_type":"markdown","metadata":{"id":"5VHkXnbJa7XR"},"source":["# Задание:\n","\n","Реализуйте нейронку для обнаружения фигур на шахматной доске:\n","\n","1. Подгрузите базу, запустив ячейку ниже. База содержит папки: \"Изображения\", \"Аннотации\", а также файл obj.names с именами классов.\n","2. Самостоятельно сформируйте список аннотаций, приведя его в такой же вид, как в ноутбуке занятия.\n","3. Самостоятельно напишите все необходимые функции (можно подсматривать в ноутбук занятия), создайте и обучите модель YOLOv3. Возьмите 10% на проверочную выборку. Добейтесь минимальной ошибки на проверочной выборке.\n","4. Самостоятельно напишите функцию отрисовки bboxes на картинках. Используя обученную вами модель, отрисуйте предсказанные bboxes на любых 5 картинках из тестового набора. Bboxes обязательно должны содержать название и вероятность класса объекта.\n","\n","\n","        Пожалуйста, перед выполнением ДЗ, запустите раздел \"Подготовка\".\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zQCkFeDfC1r1"},"source":["## Подготовка"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LCpzdzWW73rj"},"outputs":[],"source":["import time\n","import random\n","import tensorflow as tf\n","import tensorflow.keras.backend as K\n","from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LambdaCallback, CSVLogger\n","from keras.utils.vis_utils import plot_model\n","from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n","from PIL import Image, ImageDraw, ImageFont\n","\n","import struct\n","import gdown\n","\n","import numpy as np\n","from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D, Lambda\n","from tensorflow.keras.optimizers import Adam\n","from keras.layers import add, concatenate\n","from keras.models import Model\n","from keras.models import load_model\n","from itertools import repeat\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.preprocessing import image\n","\n","from matplotlib.patches import Rectangle\n","\n","from glob import glob\n","import os\n","\n","from matplotlib import pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NXBg6RtokD3l"},"outputs":[],"source":["# Загрузка базы\n","gdown.download('https://storage.yandexcloud.net/terraai/sources/chess.zip', output=None, quiet=True)\n","\n","!unzip -q chess.zip\n","!rm 'chess.zip'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25376,"status":"ok","timestamp":1668099135859,"user":{"displayName":"Vafelka","userId":"11276804272897708630"},"user_tz":-180},"id":"qP4R6cQgdGcn","outputId":"fee2243e-981e-4876-e144-ad42abb960c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"2Lkc6tVKC4ZN"},"source":["## Решение"]},{"cell_type":"markdown","metadata":{"id":"T_9FtnroC6S8"},"source":["Извлечём нужные нам данные:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1668097935485,"user":{"displayName":"Vafelka","userId":"11276804272897708630"},"user_tz":-180},"id":"uiU8EJ2fPBLq","outputId":"9173684d-0ed4-4eb8-f44f-9ece554ece1c"},"outputs":[{"name":"stdout","output_type":"stream","text":["634 634\n","\n"]},{"data":{"text/plain":["('00bc0cacffdebe6b11bdeec56f63ee49_jpg.rf.1a1407058a6170f001f2c269411d31d3.txt',\n"," '00bc0cacffdebe6b11bdeec56f63ee49_jpg.rf.1a1407058a6170f001f2c269411d31d3.jpg')"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["path = '/content/Изображения/'\n","img_names = sorted(os.listdir(path))\n","annot_path = '/content/Аннотации/'\n","annot_names = sorted(os.listdir(annot_path))\n","\n","\n","print(len(img_names), len(annot_names))\n","print()\n","\n","# Проверяем, что названия аннотаций совпадают с названием изображений\n","annot_names[0], img_names[0]"]},{"cell_type":"markdown","metadata":{"id":"sX7uoRvCPhrZ"},"source":["Названия классов"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RXWuq8VYYwGh"},"outputs":[],"source":["classes = ['black-knight', 'white-rook',\n","           'white-pawn', 'white-king',\n","           'white-bishop', 'black-rook',\n","           'black-pawn', 'black-king',\n","           'black-bishop', 'black-queen',\n","           'white-queen', 'white-knight',\n","           'bishop']"]},{"cell_type":"markdown","metadata":{"id":"teYWT_AZPxyP"},"source":["Приведём аннотации к такому же виду, как в занятии: `[имя файла с картинкой] [x,y,w,h,c] [x,y,w,h,c] ...`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1668098368797,"user":{"displayName":"Vafelka","userId":"11276804272897708630"},"user_tz":-180},"id":"ehuudzvxmCo9","outputId":"35737e78-3a5a-42c0-dc40-3dac77beaccc"},"outputs":[{"name":"stdout","output_type":"stream","text":["3730ef213ac6aad431475a9ab28f349a_jpg.rf.7529be3c45ccff8446d9464f88f8d1ae.jpg 239,2,263,50,5\n"]}],"source":["def form_datafile(image_list,annot_list):\n","  assert len(image_list) == len(annot_list), 'List lengths are not equal'\n","\n","  data = []\n","  for i in range(len(image_list)):\n","    with open(f'{annot_path}{annot_list[i]}', 'r') as inf:\n","      box_inf =  inf.readline().strip()     # Strip нужен чтобы в конце строки не вылазила мерзкое \\n,\n","                                            # которое мне портит прцесс обучения\n","\n","      data_string = f'{image_list[i]} {box_inf}'\n","      data.append(data_string)\n","\n","\n","  return np.array(data)\n","annot_list = form_datafile(img_names,annot_names)\n","print(annot_list[133])"]},{"cell_type":"markdown","metadata":{"id":"r5c9zxqKEvmG"},"source":["## Необходимые функции"]},{"cell_type":"markdown","metadata":{"id":"uLe4rFICBx4A"},"source":["Функция генерации данных. На вход приходят аннотации, на выходе получаем порцию данных для обучения."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_An_qWKXTeAX"},"outputs":[],"source":["def data_generator(annotation_lines, batch_size, anchors, input_shape):\n","\n","    ''' Функция генерации данных\n","        Args:\n","            annotation_lines -\n","            batch_size -\n","            anchors -\n","            input_shape -\n","        Return:\n","            порция данных для обучения\n","\n","        '''\n","\n","    n = len(annotation_lines) # Получаем количество элементов в словаре аннотаций\n","    i = 0 # Задаем начальный индекс\n","\n","    while True:\n","\n","        image_data = [] # Массив для хранения изображений 416х416\n","        box_data = [] # Массив для хранения bounding_box данных\n","\n","        for b in range(batch_size): # Пробегаем по всему batch_size\n","\n","            if i==0: # Если первая итерация цикла\n","                np.random.shuffle(annotation_lines) # Перемешиваем элементы\n","\n","            # Делаем аугментацию картинок и ограничивающих рамок\n","            image, box = augmentation(annotation_lines[i])\n","\n","            # Добавляем полученную картинку в результирующий массив\n","            image_data.append(image)\n","\n","            # Добавляем полученную ограничивающую рамку в массив bounfing_box\n","            box_data.append(box)\n","\n","            # Обновляем значение индека (не превышая общего количества элементов)\n","            i = (i+1) % n\n","\n","        # Преобразуем в numpy\n","        image_data = np.array(image_data)\n","        box_data = np.array(box_data)\n","\n","        # По значению ограничивающей рамки получаем y_true\n","        y_true = get_y(box_data, anchors, input_shape)\n","\n","        yield [image_data, *y_true], np.zeros(batch_size)"]},{"cell_type":"markdown","metadata":{"id":"SgfOujLkB_zc"},"source":["Функция, аугментирующая изображения случайным образом."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ejAomt0hTvdX"},"outputs":[],"source":["def augmentation(data):\n","\n","    ''' Функция случайной аугментации данных\n","        Args:\n","            annotation_lines -\n","            batch_size -\n","            anchors -\n","            input_shape -\n","        Return:\n","            порция данных для обучения\n","\n","        '''\n","\n","    # Словарь с параметрами аугментации\n","    params = {\n","        'jitter' : .3,\n","        'hue'    : .1,\n","        'sat'    : 1.5,\n","        'val'    : 1.5\n","    }\n","\n","    # Сплитим входную строку словаря\n","    data = data.split()\n","\n","    # Открываем изображение самолета\n","    image = Image.open(path + data[0])\n","\n","    # Получаем ширину и высоту оригинального изображения\n","    width_i, height_i = image.size\n","\n","    # Получаем ширину и высоту входного изображения для модели RetinaNet\n","    widht_shape, height_shape = input_shape[:2]\n","\n","    # Получаем координаты ограничивающей рамки\n","    box = np.array([np.array(list(map(lambda x: int(float(x)),box.split(',')))) for box in data[1:]])\n","\n","    # Случайным образом масштабируем изображение\n","    new_ar = widht_shape / height_shape * rand(1 - params['jitter'], 1 + params['jitter']) / rand(1 - params['jitter'], 1 + params['jitter'])\n","    scale = rand(.65, 2)\n","    if new_ar < 1:\n","        nh = int(scale * height_shape)\n","        nw = int(nh * new_ar)\n","    else:\n","        nw = int(scale * widht_shape)\n","        nh = int(nw / new_ar)\n","    image = image.resize((nw, nh), Image.BICUBIC)\n","\n","    # Преобразуем картинку к input_shape и размещаем случайным образом\n","    dx = int(rand(0, widht_shape - nw))\n","    dy = int(rand(0, height_shape - nh))\n","    new_image = Image.new('RGB', (widht_shape, height_shape), (128,128,128))\n","    new_image.paste(image, (dx, dy))\n","    image = new_image\n","\n","    # С вероятностью 50% отображаем по горизонтале\n","    flip = rand() < .5\n","    if flip:\n","        image = image.transpose(Image.FLIP_LEFT_RIGHT)\n","\n","    # Случайным образом меняем освещенность, экспозицию, гамму изображения\n","    hue1 = rand(-params['hue'], params['hue'])\n","    sat1 = rand(1, params['sat']) if rand() < .5 else 1 / rand(1, params['sat'])\n","    val1 = rand(1, params['val']) if rand() < .5 else 1 / rand(1, params['val'])\n","    x = rgb_to_hsv(np.array(image) / 255.)\n","    x[..., 0] += hue1\n","    x[..., 0][x[..., 0] > 1] -= 1\n","    x[..., 0][x[..., 0] < 0] += 1\n","    x[..., 1] *= sat1\n","    x[..., 2] *= val1\n","    x[x > 1] = 1\n","    x[x < 0] = 0\n","    image_data = hsv_to_rgb(x) # Получаем окончательный массив\n","\n","    max_boxes = 4 # Устанавливаем максимальное количество рамок на изображении\n","\n","    # Корректируем параметры ограничивающей рамки в соответсвии с проведенными выше преобразованиями\n","    box_data = np.zeros((max_boxes,5)) # Создаем массив из нулей размерностью (max_boxes, 5)\n","\n","    if len(box)>0:\n","        # Ресайзим и перемещаем\n","        box[:, [0,2]] = box[:, [0,2]] * nw/width_i + dx\n","        box[:, [1,3]] = box[:, [1,3]] * nh/height_i + dy\n","\n","        # Отражаем по горизонтале\n","        if flip: box[:, [0,2]] = widht_shape - box[:, [2,0]]\n","        box[:, 0:2][box[:, 0:2]<0] = 0\n","\n","        # Ограничиваем, если вышли за пределы input_shape\n","        box[:, 2][box[:, 2] > widht_shape] = widht_shape\n","        box[:, 3][box[:, 3] > height_shape] = height_shape\n","\n","        # Считаем высоту и ширину рамок и оставляем только те, значения которых больше 1\n","        box_w = box[:, 2] - box[:, 0] # xRight - xLeft\n","        box_h = box[:, 3] - box[:, 1] # yBottom - yTop\n","        box = box[np.logical_and(box_w > 1, box_h > 1)]\n","\n","        if len(box) > max_boxes: # Оставляем только max_boxes рамок\n","            box = box[:max_boxes]\n","        box_data[:len(box)] = box # Записываем данные в box_data\n","\n","    return image_data, box_data # Возвращаем аугментированные изображение и bounding_box"]},{"cell_type":"markdown","metadata":{"id":"YKAfm1wtCQ0N"},"source":["Функция для формирования выборки y_true - целевых значений для модели."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x57FoMtvTz_X"},"outputs":[],"source":["def get_y(true_boxes, anchors, input_shape):\n","\n","    ''' Функция подсчета y\n","        Args:\n","            true_boxes -\n","            anchors -\n","            input_shape -\n","        Return:\n","            ???\n","\n","        '''\n","    # Получаем количество анкоров для каждого уровня сеток\n","    num_layers = len(anchors) // 3\n","\n","    # Задаем маску анкоров для каждого уровня\n","    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]]\n","\n","    # Преобразуем bounding_box в numpy\n","    true_boxes = np.array(true_boxes, dtype='float32')\n","\n","    # Преобразуем input_shape в numpy\n","    input_shape = np.array(input_shape, dtype='int32')\n","\n","    # Получаем координаты центра bounding_box (xRight+xLeft / 2)\n","    boxes_xy = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) // 2\n","\n","    # Получаем ширину и высоту bounding_box (xRight - xLeft)\n","    boxes_wh = true_boxes[..., 2:4] - true_boxes[..., 0:2]\n","\n","    # Получаем координаты центра bounding_box в относительных координатах\n","    true_boxes[..., 0:2] = boxes_xy / input_shape[::-1]\n","\n","    # Получаем высоту и ширину bounding_box В относительных значениях\n","    true_boxes[..., 2:4] = boxes_wh / input_shape[::-1]\n","\n","    # Получаем количество элементов в batch_size\n","    m = true_boxes.shape[0]\n","\n","    # Создаем список из трех элементов ([13, 13], [26, 26], [52, 52])\n","    grid_shapes = [input_shape//{0:32, 1:16, 2:8}[l] for l in range(num_layers)]\n","\n","    # Создаем 0-вые списки для y_true\n","    # y_true[0].shape = (None, 13, 13, 3, 6)\n","    # y_true[1].shape = (None, 26, 26, 3, 6)\n","    # y_true[2].shape = (None, 52, 52, 3, 6)\n","    y_true = [np.zeros((m,grid_shapes[l][0],grid_shapes[l][1],len(anchor_mask[l]),5+num_classes),\n","        dtype='float32') for l in range(num_layers)]\n","\n","    anchors = np.expand_dims(anchors, 0) # Добавляем размерность\n","\n","    # Параметры для IoU\n","    anchor_maxes = anchors / 2.\n","    anchor_mins = -anchor_maxes\n","    valid_mask = boxes_wh[..., 0] > 0\n","\n","    for b in range(m):\n","\n","        wh = boxes_wh[b, valid_mask[b]] # Получаем ширину и высоту текущего bounding_box\n","\n","        if len(wh)==0: continue # Выходим если она нулевая\n","\n","        wh = np.expand_dims(wh, -2) # Добавляем размерность\n","\n","        # Параметры для IoU\n","        box_maxes = wh / 2.\n","        box_mins = -box_maxes\n","\n","        intersect_mins = np.maximum(box_mins, anchor_mins)\n","        intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n","        intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n","        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n","        box_area = wh[..., 0] * wh[..., 1]\n","        anchor_area = anchors[..., 0] * anchors[..., 1]\n","        iou = intersect_area / (box_area + anchor_area - intersect_area)\n","\n","        best_anchor = np.argmax(iou, axis=-1) # Находим лучшее значение iou для всех анкоров\n","\n","        for t, n in enumerate(best_anchor):\n","\n","            for l in range(num_layers):\n","\n","                if n in anchor_mask[l]:\n","                    i = np.floor(true_boxes[b,t,0] * grid_shapes[l][1]).astype('int32')\n","                    j = np.floor(true_boxes[b,t,1] * grid_shapes[l][0]).astype('int32')\n","                    k = anchor_mask[l].index(n)\n","                    c = true_boxes[b,t, 4].astype('int32')\n","                    y_true[l][b, j, i, k, 0:4] = true_boxes[b,t, 0:4]\n","                    y_true[l][b, j, i, k, 4] = 1\n","                    y_true[l][b, j, i, k, 5+c] = 1\n","\n","    return y_true"]},{"cell_type":"markdown","metadata":{"id":"tqNUm0oaCif9"},"source":["Функция-рандомайзер. Будем использовать в функции augmentation для добавления фактора случайности."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x08n2YLPChyX"},"outputs":[],"source":["def rand(a=0, b=1):\n","\n","    return np.random.rand()*(b-a) + a"]},{"cell_type":"markdown","metadata":{"id":"tn-iRjBDC3wm"},"source":["Стандартная функция ошибки yolo_loss."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KQKCyjqp6IRB"},"outputs":[],"source":["# Обозначим путь для весов\n","weights_path = '/content/drive/MyDrive/yolov3.h5'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SeNZp2mJlJI_"},"outputs":[],"source":["def yolo_loss(inputs, num_anchors):\n","\n","    ''' Функция рассчитывает отношение пересечение над объединениеми.\n","        Args:\n","            box1 - координаты рамки.\n","            box2 - координаты рамки.\n","        Return:\n","            значение ошибки IoU.\n","        '''\n","    # Порог вероятности обнаружения объекта\n","    ignore_thresh = .5\n","\n","    # Подсчитываем количество анкоров на каждом уровне сетки\n","    num_layers = num_anchors // 3\n","\n","    # Из входных данных выцепляем посчитанные моделью значения\n","    y_pred = inputs[:num_layers]\n","\n","    # Из входных данных выцепляем эталонные значения\n","    y_true = inputs[num_layers:]\n","\n","    # Задаем маску анкоров для каждого уровня сеток\n","    anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n","\n","    # Получаем размерность входного изображения ( (13 х 13) * 32 = (416 х 416)) и приводим к типу элемента y_true[0]\n","    input_shape = K.cast(K.shape(y_pred[0])[1:3] * 32, K.dtype(y_true[0]))\n","\n","    # Получаем двумерный массив, соответствующий размерностям сеток ((13, 13), (26, 26), (52, 52))\n","    grid_shapes = [K.cast(K.shape(y_pred[l])[1:3], K.dtype(y_true[0])) for l in range(num_layers)]\n","\n","    loss = 0 # Значение ошибки\n","\n","    # Размер пакета\n","    m = K.shape(y_pred[0])[0]\n","\n","    # Преобразуем к типу y_pred[0]\n","    batch_size = K.cast(m, K.dtype(y_pred[0]))\n","\n","    for l in range(num_layers): # Пробегаем по всем трем уровням сеток\n","\n","        # Получаем маску для сетки l-го уровня по вероятности определения объекта (5-ый параметр в списке общих параметров).\n","        # В массиве object_mask будут значения, которые соответствуют только вероятности обнаружения объекта\n","        object_mask = y_true[l][..., 4:5] # Вернется набор данных вида: ([0][0][0][0]...[1]...[0])\n","\n","        # Получаем аналогичную выборку для сетки l-го уровня с OHE (где записана позиция нашего класса)\n","        # В массиве true_class будут значения, которые соответсвуют только OHE представлению класса ядля данного уровня анкоров\n","        true_class = y_true[l][..., 5:] # Вернется набор данных вида: ([0][0][0][0]...[1]...[0])\n","\n","        num_sub_anchors = len(anchors[anchor_mask[l]]) # Получаем количество анкоров для отдельного уровян сетки (3)\n","\n","        # Решейпим анкоры отдельного уровня сетки и записываем в переменную anchors_tensor\n","        anchors_tensor = K.reshape(K.constant(anchors[anchor_mask[l]]), [1, 1, 1, num_sub_anchors, 2])\n","\n","        # Создаем двумерный массив grid со значениями [[[0, 0] , [0, 1] , [0, 2] , ... , [0, k]],\n","        #                                             [[1, 0] , [1, 1] , [1, 2] , ... , [1 ,k]],\n","        #                                             ...\n","        #                                             [[k, 0] , [k, 1] , [k, 2] , ... , [k, k]]]\n","        # где k - размерность сетки. Массив хранит индексы ячеек сетки\n","        grid_shape = K.shape(y_pred[l])[1:3] # Получаем ширину и высоту сетки\n","        grid_y = K.tile(K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),[1, grid_shape[1], 1, 1]) # Создаем вертикальную линию\n","        grid_x = K.tile(K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),[grid_shape[0], 1, 1, 1]) # Создаем горизонтальную линию\n","        grid = K.concatenate([grid_x, grid_y]) # Объединяем\n","        grid = K.cast(grid, K.dtype(y_pred[l])) # Приводим к типу y_pred[l]\n","\n","        # Решейпим y_pred[l]                 13                13              3              6\n","        feats = K.reshape(y_pred[l], [-1, grid_shape[0], grid_shape[1], num_sub_anchors, num_classes + 5])\n","\n","        # -- Считаем ошибку в определении координат центра объекта\n","\n","        # Получаем координаты центра объекта из спредиктенного значения\n","        pred_xy = (K.sigmoid(feats[..., :2]) + grid) / K.cast(grid_shape[::-1], K.dtype(feats)) # три точки ... означают, что мы берем все параметры до запятой ,\n","        # Производим обратные вычесления для оригинальных значений из y_true для координат центра объекта\n","        true_xy = y_true[l][..., :2] * grid_shapes[l][::-1] - grid  # Реальные координаты центра bounding_box\n","        box_loss_scale = 2 - y_true[l][...,2:3] * y_true[l][...,3:4] # чем больше бокс, тем меньше ошибка\n","        # binary_crossentropy для истинного значения и спредиктенного (obect_mask для подсчета только требуемого значения)\n","        xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(true_xy, feats[...,0:2], from_logits=True)\n","\n","        # --- Считаем ошибку в определении координат ширины и высоты\n","\n","        # Получаем значения ширины и высоты изображения из спредиктенного значения\n","        pred_wh = K.exp(feats[..., 2:4]) * anchors_tensor / K.cast(input_shape[::-1], K.dtype(feats))\n","        # Производим обратные вычесления для оригинальных значений из y_true для ширины и высоты объекта\n","        true_wh = K.log(y_true[l][..., 2:4] / anchors[anchor_mask[l]] * input_shape[::-1])\n","        # Оставляем значение высоты и ширины только у тех элементов, где object_mask = 1\n","        true_wh = K.switch(object_mask, true_wh, K.zeros_like(true_wh))\n","        # Считаем значение ошибки в определении высоты и ширины\n","        wh_loss = object_mask * box_loss_scale * 0.5 * K.square(true_wh-feats[...,2:4])\n","\n","        # Объединяем значения в один  массив\n","        pred_box = K.concatenate([pred_xy, pred_wh])\n","\n","        # Считаем ошибку в определении обнаружения какого-либо класса\n","        # Для этого вначале надо отсечь все найденные объекты, вероятность которых меньше установленного значения ignore_thresh\n","\n","        # Определяем массив, который будет хранить данные о неподходящих значениях\n","        ignore_mask = tf.TensorArray(K.dtype(y_true[0]), size=1, dynamic_size=True)\n","        object_mask_bool = K.cast(object_mask, 'bool') # Приводим тип object_mask к типу 'bool'\n","\n","        # Функция, определяющая данные, которые требуется игнорировать\n","        # Пробегаем по всем элементам пакета (b<m)\n","        # Получаем параметры реального bounding_box для текущей ячейки\n","        # Считаем IoU реального и спредиктенного\n","        # В зависимости от best_iou < ignore_thresh помечаем его как верно распознанный или неверено\n","\n","        def loop_body(b, ignore_mask):\n","\n","            '''\n","            Функция рассчитывает отношение пересечение над объединениеми.\n","            Args:\n","                b - элемент пакета\n","                ignore_mask - координаты рамки.\n","            Return:\n","                b+1 - следующий элемент пакета\n","                ignore_mask - координаты рамки.\n","             '''\n","\n","            # в true_box запишутся первыые 4 параметра (центр, высота и ширина объекта) того элемента, значение которого в object_mask_bool равно True\n","            true_box = tf.boolean_mask(y_true[l][b,...,0:4], object_mask_bool[b,...,0])\n","\n","            # Подсчитываем iou для спредиктенной ограничивающей рамки (pred_box) и оригинальной (true_box)\n","            iou = calc_iou(pred_box[b], true_box)\n","\n","            # Находим лучшую ограничивающую рамку\n","            best_iou = K.max(iou, axis=-1)\n","\n","            # Записываем в ignore_mask true или false в зависимости от (best_iou < ignore_thresh)\n","            ignore_mask = ignore_mask.write(b, K.cast(best_iou < ignore_thresh, K.dtype(true_box)))\n","\n","            return b+1, ignore_mask\n","\n","        # Пробегаем в цикле по всем элементам в пределах значения m (m = batch size)\n","        _, ignore_mask = tf.while_loop(lambda b,*args: b<m, loop_body, [0, ignore_mask])\n","        ignore_mask = ignore_mask.stack() # Приводим ignore_mask к тензору\n","        ignore_mask = K.expand_dims(ignore_mask, -1) # Добавляем еще одну размерность в конце ignore_mask\n","\n","        # Считаем значение ошибки\n","        # 1 компонента - для значений, которые были верно спредиктены\n","        # 2 компонентя - для значения, которые были неверно спредиктены\n","        confidence_loss = (\n","            object_mask * K.binary_crossentropy(object_mask, feats[...,4:5], from_logits=True) +\n","            (1-object_mask) * K.binary_crossentropy(object_mask, feats[...,4:5], from_logits=True) * ignore_mask\n","            )\n","\n","        # Считаем ошибку в определении класса объекта\n","        class_loss = object_mask * K.binary_crossentropy(true_class, feats[...,5:], from_logits=True)\n","\n","        # Считаем суммарную ошибку\n","        xy_loss = K.sum(xy_loss) / batch_size\n","        wh_loss = K.sum(wh_loss) / batch_size\n","        confidence_loss = K.sum(confidence_loss) / batch_size\n","        class_loss = K.sum(class_loss) / batch_size\n","        loss += xy_loss + wh_loss + confidence_loss + class_loss\n","\n","    return loss # Возвращаем значение ошибки"]},{"cell_type":"markdown","metadata":{"id":"yF3EspclDDlW"},"source":["Функция подсчета коэффициента пересечения IoU."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OvedY10mDEWX"},"outputs":[],"source":["def calc_iou(input1, input2):\n","\n","    ''' Функция подсчета коэффициента пересечения IoU\n","        Args:\n","            input1 -\n","            input2 -\n","        Return:\n","            ошибка IoU\n","\n","        '''\n","\n","    # Добавляем одну размерность\n","    input1 = K.expand_dims(input1, -2)\n","    input2 = K.expand_dims(input2, 0)\n","\n","    # Получаем координаты x,y центра\n","    xy1 = input1[..., :2]\n","    xy2 = input2[..., :2]\n","\n","    # Получаем значения высоты и ширины\n","    wh1 = input1[..., 2:4]\n","    wh2 = input2[..., 2:4]\n","\n","    # Делим значения высоты и ширины пополам\n","    wh_half1 = wh1 / 2.\n","    wh_half2 = wh2 / 2.\n","\n","    # Получаем значение, соответствующее верхнему левому углу\n","    top_left1 = xy1 - wh_half1\n","    top_left2 = xy2 - wh_half2\n","\n","    # Получаем значение, соотвествующее правому нижнему углу\n","    right_bottom1 = xy1 + wh_half1\n","    right_bottom2 = xy2 + wh_half2\n","\n","    # Берем максимальные координаты из левых верхних углов\n","    intersect_mins = K.maximum(top_left1, top_left2)\n","\n","    # Берем Минимальные координаты координаты из правых нижних углов\n","    intersect_maxes = K.minimum(right_bottom1, right_bottom2)\n","\n","    # Считаем ширину и высоту области пересечения\n","    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n","\n","    # Считаем площадь области пересечения\n","    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n","\n","    # Считаем площадь первых элементов\n","    area1 = wh1[..., 0] * wh1[..., 1]\n","\n","    # Считаем площадь вторых элементов\n","    area2 = wh2[..., 0] * wh2[..., 1]\n","\n","    return intersect_area / (area1 + area2 - intersect_area)"]},{"cell_type":"markdown","metadata":{"id":"WbTIPRD8DMcd"},"source":["Определяем сверточный блок с нормализацией и активацией."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KayoU8ZuEZwD"},"outputs":[],"source":["def DBL(x, filters, kernel, strides=1, batch_norm=True, layer_idx=None): # DarknetConv2D_BN_Leaky\n","\n","    '''\n","    Функция реализует блок DBL в составе моделей Darknet и YOLO\n","\n","    Args:\n","        x - тензор входных данных\n","        filter - количество фильтров на слой, целое число\n","        kernel - размер ядра свертки, целое число\n","        stride - шаг свертки, целое число\n","        batch_norm - включать или ветку со слоем Batchnormalization и активационной функцией LeakyReLu.\n","        layer_idx - номер слоя\n","\n","    Return:\n","        x - тензор выходных данных\n","        layer_idx+1 -номер следующего слоя\n","\n","    '''\n","\n","    if strides == 1:\n","        padding = 'same'\n","    else:\n","        x = ZeroPadding2D(((1, 0), (1, 0)))(x)  # Делаем oтступ в виде нулей по контуру изображения, что бы захватить левый верхний угол\n","        padding = 'valid'\n","    x = Conv2D(filters=filters, kernel_size=kernel,\n","              strides=strides, padding=padding,\n","              use_bias=not batch_norm, kernel_regularizer=l2(0.0005), name='conv_' + str(layer_idx))(x)\n","    if batch_norm:\n","        x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(layer_idx))(x)\n","        x = LeakyReLU(alpha=0.1,name='leake_' + str(layer_idx))(x)\n","\n","    return x, layer_idx+1"]},{"cell_type":"markdown","metadata":{"id":"n-6wt1XZDu_F"},"source":["Определяем минимальную ячейку Residual блока."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9AE9IQj3DUvY"},"outputs":[],"source":["def Res_unit(x, filters, layer_idx): # DarknetResidual\n","\n","    '''\n","    Функция определяет минимальную ячейку Residual блока\n","\n","    Args:\n","        x - тензор входных данных\n","        filter - количество фильтров на слой, целое число\n","        layer_idx - номер слоя\n","\n","    Return:\n","        x - тензор выходных данных\n","        layer_idx+1 - номер следующего слоя\n","\n","    '''\n","\n","    skip_connection = x\n","    x, layer_idx = DBL(x, filters // 2, kernel=1, layer_idx=layer_idx)\n","    x, layer_idx = DBL(x, filters, kernel=3, layer_idx=layer_idx)\n","    x = add([skip_connection , x], name='Add_'+str(layer_idx))\n","\n","    return x, layer_idx+1"]},{"cell_type":"markdown","metadata":{"id":"f8FebAg3EQKV"},"source":["Определяем Residual блок состоящий из входного сверточного слоя и последовательности Res_unit блоков."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D3sCrf7cDYo1"},"outputs":[],"source":["def ResBlock(x, filters, blocks, layer_idx): # DarknetBlock\n","\n","    '''\n","    Функция определяет Residual блок состоящий из входного сверточного слоя\n","    и последовательности Res_unit блоков\n","\n","    Args:\n","        x - тензор входных данных\n","        filters - задает количество фильтров\n","        block - задает количество Residual 'ячеек', а именно, сколько раз повторить в цикле функцию Res_unit\n","        layer_idx - номер слоя\n","\n","    Return:\n","        x - тензор выходных данных\n","        layer_idx -номер слоя\n","\n","    '''\n","\n","    x, layer_idx = DBL(x, filters, kernel=3, strides=2, layer_idx=layer_idx)\n","\n","    for _ in repeat(None, blocks):\n","        x, layer_idx = Res_unit(x, filters, layer_idx=layer_idx)\n","\n","    return x, layer_idx"]},{"cell_type":"markdown","metadata":{"id":"ExUQYdq_Ds31"},"source":["Блок для получения предсказаний конкретного уровня анкоров. В финальной модели будет 3 таких блока, по одному на каждый уровень анкоров."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"49JWSxkmDZrF"},"outputs":[],"source":["def Detector(x_in, filters, layer_idx=None):\n","\n","    '''\n","    Функция реализует блок DBL в составе моделей Darknet и YOLO\n","\n","    Args:\n","        x_in - тензор или список тензоров\n","        filters - количество фильтров\n","        layer_idx - номер следующего сверточного слоя\n","\n","    Return:\n","        bboxes - рамки\n","        fork - тензор\n","        layer_idx -номер слоя\n","\n","    '''\n","\n","    if isinstance(x_in, list): # Если на вход поступает список попадаем в эту ветку (маршруты 2 и 3)\n","        x, x_skip = x_in[0], x_in[1]# Разбиваем список на отдельные тензоры\n","        x,layer_idx = DBL(x, filters, kernel=1, strides=1, layer_idx=layer_idx) # DarknetConv\n","        x = UpSampling2D(2, name = 'UpSampling_' + str(layer_idx))(x) # Повышаем размерность тензора\n","        layer_idx+=1\n","        x =concatenate([x, x_skip], name = 'Concatenate_' + str(layer_idx)) # Объединяем маршруты\n","        layer_idx+=1\n","\n","        # Пять сверточных слоев DBL*5\n","        for i in range(2):\n","          x, layer_idx = DBL(x, filters, 1, layer_idx=layer_idx)      # 1,3\n","          x, layer_idx = DBL(x, filters * 2, 3, layer_idx=layer_idx)  # 2,4\n","\n","        fork, layer_idx = DBL(x, filters, 1, layer_idx=layer_idx)      # 5 С пятого слоя каскада делаем вилку на выход и на другой масштаб\n","\n","    else: # В эту ветку попадает только маршрут 1\n","        x = x_in\n","\n","        # Пять сверточных слоев DBL*5\n","        for i in range(2):\n","          x, layer_idx = DBL(x, filters, 1, layer_idx=layer_idx)      # 1,3\n","          x, layer_idx = DBL(x, filters * 2, 3, layer_idx=layer_idx)  # 2,4\n","\n","        fork, layer_idx = DBL(x, filters, 1, layer_idx=layer_idx)      # 5 С пятого слоя каскада делаем вилку на выход и на другой масштаб\n","\n","    # Предпоследний сверточный слой (№80 13х13х1024, #92 26x26x512, #104 52x52x256)\n","    x,layer_idx = DBL(fork, filters=filters*2, kernel=3, strides=1, layer_idx=layer_idx)\n","\n","    # Выходные слои (№81 13х13х (anchors * (4 + 1 + classes)), №93 26х26, №105 52х52 (255)\n","    bboxes, layer_idx = DBL(x, filters=num_sub_anchors * (4 + 1 + num_classes), kernel=1, strides=1, batch_norm= False, layer_idx=layer_idx)\n","\n","    return bboxes, fork, layer_idx"]},{"cell_type":"markdown","metadata":{"id":"p2VM2cekIxJP"},"source":["Функция создания каркаса модели YOLOv3. Для обучения мы будем присоединять к этому каркасу необходимые входные слои, а также Lambda-слой для вычисления функции ошибки. Для получения предсказаний, мы будем использовать только этот каркас."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3MNKRzT_Dfzk"},"outputs":[],"source":["def create_yolov3_model(inputs, num_sub_anchors, num_classes):\n","\n","    '''\n","    Функция реализует блок DBL в составе моделей Darknet и YOLO\n","\n","    Args:\n","        inputs - входной тензор\n","        num_sub_anchors - количество анкоров\n","        num_classes - количество классов\n","\n","    Return:\n","        model - модель\n","\n","    '''\n","    layer_idx = 0 # Номер первого слоя\n","    x, layer_idx = DBL(inputs, filters=32, kernel=3, layer_idx=layer_idx)       # DarknetConv 1 слой\n","    x, layer_idx = ResBlock(x, filters=64, blocks=1, layer_idx=layer_idx)            # DarknetBlock 3 слоя\n","    x, layer_idx = ResBlock(x, filters=128, blocks=2, layer_idx=layer_idx)           # DarknetBlock 5 слоя\n","    x, layer_idx = Route_1,_ = ResBlock(x, filters=256, blocks=8, layer_idx=layer_idx) # DarknetBlock 9 слоев\n","    x, layer_idx = Route_2,_ = ResBlock(x, filters=512, blocks=8, layer_idx=layer_idx) # DarknetBlock 9 слоев\n","    Route_3, layer_idx = ResBlock(x, filters=1024, blocks=4, layer_idx=layer_idx)          # последние 4 Res блока Darknet\n","\n","    # 5 сверточных слоев DBL\n","    bbox_scale_1, fork_1, layer_idx = Detector(Route_3, filters=512, layer_idx=layer_idx)\n","\n","    # 82 слой на первый выход  83 пропуск\n","    layer_idx = 84\n","    bbox_scale_2, fork_2, layer_idx = Detector([fork_1, Route_2], filters=256, layer_idx=layer_idx) # 6 слоев\n","\n","    # слои 94-95 пропущены\n","    layer_idx = 96\n","    bbox_scale_3, _, layer_idx = Detector([fork_2, Route_1], filters=128, layer_idx=layer_idx) # 6 слоев\n","\n","    model = Model (inputs, [bbox_scale_1, bbox_scale_2, bbox_scale_3])\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"BXaMWyj6FOu8"},"source":["## Создание и обучение сети"]},{"cell_type":"markdown","metadata":{"id":"AooPt7ZMJjSf"},"source":["Задаём необходимые параметры."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gVZcZawTEbji"},"outputs":[],"source":["size = 416 # Размер входного изображения для модели YOLO\n","input_shape = (size, size) # ширина, высота\n","channels= 3 # число цветовых каналов (RGB)\n","num_sub_anchors=3 # количество анкоров в каждой сетке\n","num_classes = len(classes) # чило классов в новом датасете\n","\n","anchors = np.array([[10,13], [16,30], [33,23], [30, 61], [62,45], [59,119], [116, 90], [156, 198], [373, 326]])\n","\n","num_anchors = 9 # общее количество анкоров\n","batch_size = 8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CnOGMDfYDpGG"},"outputs":[],"source":["def create_model(size, num_anchors, use_weights = False, weights_path = weights_path ):\n","\n","    ''' Функция оборачивает модель YOLO для обучения\n","\n","        Args:\n","            size - размерность входного изображения для модели YOLO\n","            num_anchors - общее количество анкоров (9)\n","            use_weights - использовать ли предобученные веса(если модель уже начали обучать)\n","            weights_path - путь к сохраненным весам модели\n","        Return:\n","            созданная модель\n","\n","            '''\n","    # Создаем входной слой модели, добавляя размерность для глубины цвета\n","    inputs = Input(shape = (size, size, 3))\n","\n","    y_true    =   [Input (shape = (size // 32, size // 32, num_anchors // 3, num_classes + 5))] # Уровень сетки 13х13 (416/32)\n","    y_true.append (Input (shape = (size // 16, size // 16, num_anchors // 3, num_classes + 5))) # Уровень сетки 26х26 (416/26)\n","    y_true.append (Input (shape = (size // 8,  size // 8,  num_anchors // 3, num_classes + 5))) # Уровень сетки 52х52 (416/8)\n","\n","    # Создаем модель YOLOv3\n","    model_yolo = create_yolov3_model(inputs, num_anchors // 3, num_classes)\n","\n","    # Выводим сообщение о создании модели\n","    print ('Создана модель YOLOv3. Количество классов: {}.'.format(num_classes))\n","\n","    # Если установлен флаг загрузки весов\n","    if use_weights:\n","\n","        # Загружаем предобученные веса\n","        model_yolo.load_weights(weights_path, by_name = False, skip_mismatch = False)\n","        # Выводим сообщение о загруженных весах\n","        print ('Загружены веса из файла {}.'.format(weights_path))\n","\n","    # Создаем выходной слой Lambda (выходом которого будет значение ошибки модели)\n","    # На вход слоя подается:\n","    #   - model_yolo.output (выход модели model_yolo (то есть то, что посчитала сеть))\n","    #   - y_true (оригинальные данные из обучающей выборки)\n","    outputs = Lambda(yolo_loss, output_shape = (1,), name = 'yolo_loss', arguments = {'num_anchors' : num_anchors}) ([*model_yolo.output, *y_true])\n","\n","    # Возвращаем модель\n","    return Model([inputs, *y_true], outputs)"]},{"cell_type":"markdown","metadata":{"id":"xCgFM8lqJmiv"},"source":["Создаем модель YOLOv3 для обучения."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4470,"status":"ok","timestamp":1668099340794,"user":{"displayName":"Vafelka","userId":"11276804272897708630"},"user_tz":-180},"id":"FCm0JLYXFUOu","outputId":"68d41661-4d9b-4c9d-a04d-218e6c9b7f65"},"outputs":[{"name":"stdout","output_type":"stream","text":["Создана модель YOLOv3. Количество классов: 13.\n"]}],"source":["model_YOLO = create_model(size, num_anchors, use_weights=False, weights_path=weights_path)"]},{"cell_type":"markdown","metadata":{"id":"iNCzoILWJsPG"},"source":["Выведем структуру модели."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1kJ-Vhu1AhBuXDH9cNK5GmkbTrAVFHqzw"},"executionInfo":{"elapsed":13401,"status":"ok","timestamp":1668099358277,"user":{"displayName":"Vafelka","userId":"11276804272897708630"},"user_tz":-180},"id":"1qEga_8pDrDU","outputId":"56358306-f8d5-4e54-877b-da1c506462aa"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["plot_model(model_YOLO, show_shapes=True)"]},{"cell_type":"markdown","metadata":{"id":"3-6h8TawJwkR"},"source":["Компилируем модель."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GKYXeuisDsoE"},"outputs":[],"source":["optimizer = Adam(learning_rate=5e-4)\n","\n","model_YOLO.compile(optimizer=optimizer, loss={'yolo_loss': lambda y_true, y_pred: y_pred})"]},{"cell_type":"markdown","metadata":{"id":"Zya8HbTbJ0om"},"source":["Делим данные на обучающую и проверочную выборку."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":113,"status":"ok","timestamp":1653038268644,"user":{"displayName":"Университет ИИ","userId":"05611982447652176761"},"user_tz":-180},"id":"0JluU8i2Duck","outputId":"77130d3a-fbc8-43a9-e8bb-70c08f9e4128"},"outputs":[{"name":"stdout","output_type":"stream","text":["63\n","571\n","(634,)\n"]}],"source":["val_split = 0.1 # Коэфициент разделения на обучающую и проверочную выборку\n","\n","num_val = int(len(annot_list) * val_split) # Количество элементов проверочной выборки\n","print (num_val)\n","\n","num_train = len(annot_list) - num_val # Количество элементов обучающей выборки\n","print (num_train)\n","\n","print (annot_list.shape)"]},{"cell_type":"markdown","metadata":{"id":"144UaI47J4tG"},"source":["Задаём колбэки и запускаем обучение."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TI3aydsMMw4r"},"outputs":[],"source":["# Скачиваем датасет с изображениями для тестирования модели\n","import gdown\n","\n","gdown.download('https://storage.yandexcloud.net/aiueducation/Content/advanced/l9/airplanes.zip', None, quiet=True)\n","\n","# Распаковываем датасет\n","!unzip -q airplanes.zip -d dataset2\n","\n","source_dir2 = 'dataset2/airplanes'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4547784,"status":"ok","timestamp":1646348369040,"user":{"displayName":"Университет искусственного интеллекта","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKwCtaFiq_5mTGvq9QYM1-sEnTJI6yV-ouy66c=s64","userId":"12454839568076823986"},"user_tz":-180},"id":"F8aY-NebEEIW","outputId":"1d47911f-b2bc-4c2b-f7fc-af4600be0c6f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","71/71 [==============================] - ETA: 0s - loss: 1530.1100\n","Epoch 1: val_loss improved from inf to 736360.50000, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 77s 716ms/step - loss: 1530.1100 - val_loss: 736360.5000 - lr: 5.0000e-04\n","Epoch 2/100\n","71/71 [==============================] - ETA: 0s - loss: 298.6007\n","Epoch 2: val_loss improved from 736360.50000 to 469.97476, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 47s 670ms/step - loss: 298.6007 - val_loss: 469.9748 - lr: 5.0000e-04\n","Epoch 3/100\n","71/71 [==============================] - ETA: 0s - loss: 158.7471\n","Epoch 3: val_loss improved from 469.97476 to 186.58322, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 47s 670ms/step - loss: 158.7471 - val_loss: 186.5832 - lr: 5.0000e-04\n","Epoch 4/100\n","71/71 [==============================] - ETA: 0s - loss: 113.2515\n","Epoch 4: val_loss improved from 186.58322 to 113.17407, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 48s 682ms/step - loss: 113.2515 - val_loss: 113.1741 - lr: 5.0000e-04\n","Epoch 5/100\n","71/71 [==============================] - ETA: 0s - loss: 87.0762\n","Epoch 5: val_loss improved from 113.17407 to 87.63319, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 47s 671ms/step - loss: 87.0762 - val_loss: 87.6332 - lr: 5.0000e-04\n","Epoch 6/100\n","71/71 [==============================] - ETA: 0s - loss: 75.0365\n","Epoch 6: val_loss improved from 87.63319 to 74.33050, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 47s 669ms/step - loss: 75.0365 - val_loss: 74.3305 - lr: 5.0000e-04\n","Epoch 7/100\n","71/71 [==============================] - ETA: 0s - loss: 68.1959\n","Epoch 7: val_loss improved from 74.33050 to 66.06414, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 47s 673ms/step - loss: 68.1959 - val_loss: 66.0641 - lr: 5.0000e-04\n","Epoch 8/100\n","71/71 [==============================] - ETA: 0s - loss: 61.9838\n","Epoch 8: val_loss improved from 66.06414 to 56.30961, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 47s 669ms/step - loss: 61.9838 - val_loss: 56.3096 - lr: 5.0000e-04\n","Epoch 9/100\n","71/71 [==============================] - ETA: 0s - loss: 55.8645\n","Epoch 9: val_loss improved from 56.30961 to 52.40961, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 47s 673ms/step - loss: 55.8645 - val_loss: 52.4096 - lr: 5.0000e-04\n","Epoch 10/100\n","71/71 [==============================] - ETA: 0s - loss: 52.3493\n","Epoch 10: val_loss improved from 52.40961 to 49.15386, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 49s 689ms/step - loss: 52.3493 - val_loss: 49.1539 - lr: 5.0000e-04\n","Epoch 11/100\n","71/71 [==============================] - ETA: 0s - loss: 50.3935\n","Epoch 11: val_loss improved from 49.15386 to 48.39339, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 47s 668ms/step - loss: 50.3935 - val_loss: 48.3934 - lr: 5.0000e-04\n","Epoch 12/100\n","71/71 [==============================] - ETA: 0s - loss: 48.5502\n","Epoch 12: val_loss improved from 48.39339 to 44.48710, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 47s 668ms/step - loss: 48.5502 - val_loss: 44.4871 - lr: 5.0000e-04\n","Epoch 13/100\n","71/71 [==============================] - ETA: 0s - loss: 45.4617\n","Epoch 13: val_loss improved from 44.48710 to 40.93151, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 47s 669ms/step - loss: 45.4617 - val_loss: 40.9315 - lr: 5.0000e-04\n","Epoch 14/100\n","71/71 [==============================] - ETA: 0s - loss: 44.0167\n","Epoch 14: val_loss did not improve from 40.93151\n","71/71 [==============================] - 44s 631ms/step - loss: 44.0167 - val_loss: 45.0566 - lr: 5.0000e-04\n","Epoch 15/100\n","71/71 [==============================] - ETA: 0s - loss: 44.0146\n","Epoch 15: val_loss did not improve from 40.93151\n","71/71 [==============================] - 44s 629ms/step - loss: 44.0146 - val_loss: 45.2968 - lr: 5.0000e-04\n","Epoch 16/100\n","71/71 [==============================] - ETA: 0s - loss: 42.1305\n","Epoch 16: val_loss did not improve from 40.93151\n","\n","Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00035000001662410796.\n","71/71 [==============================] - 45s 633ms/step - loss: 42.1305 - val_loss: 42.1349 - lr: 5.0000e-04\n","Epoch 17/100\n","71/71 [==============================] - ETA: 0s - loss: 40.7929\n","Epoch 17: val_loss improved from 40.93151 to 38.46690, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 48s 679ms/step - loss: 40.7929 - val_loss: 38.4669 - lr: 3.5000e-04\n","Epoch 18/100\n","71/71 [==============================] - ETA: 0s - loss: 40.0211\n","Epoch 18: val_loss improved from 38.46690 to 37.94250, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 47s 664ms/step - loss: 40.0211 - val_loss: 37.9425 - lr: 3.5000e-04\n","Epoch 19/100\n","71/71 [==============================] - ETA: 0s - loss: 38.9600\n","Epoch 19: val_loss did not improve from 37.94250\n","71/71 [==============================] - 44s 630ms/step - loss: 38.9600 - val_loss: 38.5402 - lr: 3.5000e-04\n","Epoch 20/100\n","71/71 [==============================] - ETA: 0s - loss: 38.5047\n","Epoch 20: val_loss improved from 37.94250 to 36.21965, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 48s 679ms/step - loss: 38.5047 - val_loss: 36.2196 - lr: 3.5000e-04\n","Epoch 21/100\n","71/71 [==============================] - ETA: 0s - loss: 37.6729\n","Epoch 21: val_loss did not improve from 36.21965\n","71/71 [==============================] - 44s 618ms/step - loss: 37.6729 - val_loss: 36.8356 - lr: 3.5000e-04\n","Epoch 22/100\n","71/71 [==============================] - ETA: 0s - loss: 37.1623\n","Epoch 22: val_loss improved from 36.21965 to 34.36354, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 46s 654ms/step - loss: 37.1623 - val_loss: 34.3635 - lr: 3.5000e-04\n","Epoch 23/100\n","71/71 [==============================] - ETA: 0s - loss: 36.7149\n","Epoch 23: val_loss improved from 34.36354 to 33.71767, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 46s 659ms/step - loss: 36.7149 - val_loss: 33.7177 - lr: 3.5000e-04\n","Epoch 24/100\n","71/71 [==============================] - ETA: 0s - loss: 36.0721\n","Epoch 24: val_loss did not improve from 33.71767\n","71/71 [==============================] - 43s 616ms/step - loss: 36.0721 - val_loss: 48.6027 - lr: 3.5000e-04\n","Epoch 25/100\n","71/71 [==============================] - ETA: 0s - loss: 35.7205\n","Epoch 25: val_loss improved from 33.71767 to 32.94171, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 46s 656ms/step - loss: 35.7205 - val_loss: 32.9417 - lr: 3.5000e-04\n","Epoch 26/100\n","71/71 [==============================] - ETA: 0s - loss: 34.8983\n","Epoch 26: val_loss improved from 32.94171 to 32.11704, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 46s 649ms/step - loss: 34.8983 - val_loss: 32.1170 - lr: 3.5000e-04\n","Epoch 27/100\n","71/71 [==============================] - ETA: 0s - loss: 35.2334\n","Epoch 27: val_loss did not improve from 32.11704\n","71/71 [==============================] - 44s 620ms/step - loss: 35.2334 - val_loss: 34.0574 - lr: 3.5000e-04\n","Epoch 28/100\n","71/71 [==============================] - ETA: 0s - loss: 33.5665\n","Epoch 28: val_loss did not improve from 32.11704\n","71/71 [==============================] - 43s 616ms/step - loss: 33.5665 - val_loss: 32.7055 - lr: 3.5000e-04\n","Epoch 29/100\n","71/71 [==============================] - ETA: 0s - loss: 33.7132\n","Epoch 29: val_loss did not improve from 32.11704\n","\n","Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n","71/71 [==============================] - 44s 618ms/step - loss: 33.7132 - val_loss: 33.9525 - lr: 3.5000e-04\n","Epoch 30/100\n","71/71 [==============================] - ETA: 0s - loss: 33.4147\n","Epoch 30: val_loss improved from 32.11704 to 29.77136, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 48s 676ms/step - loss: 33.4147 - val_loss: 29.7714 - lr: 2.4500e-04\n","Epoch 31/100\n","71/71 [==============================] - ETA: 0s - loss: 32.1957\n","Epoch 31: val_loss did not improve from 29.77136\n","71/71 [==============================] - 44s 621ms/step - loss: 32.1957 - val_loss: 33.1160 - lr: 2.4500e-04\n","Epoch 32/100\n","71/71 [==============================] - ETA: 0s - loss: 31.6877\n","Epoch 32: val_loss did not improve from 29.77136\n","71/71 [==============================] - 44s 622ms/step - loss: 31.6877 - val_loss: 32.2015 - lr: 2.4500e-04\n","Epoch 33/100\n","71/71 [==============================] - ETA: 0s - loss: 31.4662\n","Epoch 33: val_loss did not improve from 29.77136\n","\n","Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00017150000203400848.\n","71/71 [==============================] - 44s 628ms/step - loss: 31.4662 - val_loss: 32.9480 - lr: 2.4500e-04\n","Epoch 34/100\n","71/71 [==============================] - ETA: 0s - loss: 30.8475\n","Epoch 34: val_loss did not improve from 29.77136\n","71/71 [==============================] - 44s 628ms/step - loss: 30.8475 - val_loss: 29.9208 - lr: 1.7150e-04\n","Epoch 35/100\n","71/71 [==============================] - ETA: 0s - loss: 30.1237\n","Epoch 35: val_loss did not improve from 29.77136\n","71/71 [==============================] - 44s 626ms/step - loss: 30.1237 - val_loss: 30.1134 - lr: 1.7150e-04\n","Epoch 36/100\n","71/71 [==============================] - ETA: 0s - loss: 30.1888\n","Epoch 36: val_loss did not improve from 29.77136\n","\n","Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00012004999734926967.\n","71/71 [==============================] - 44s 630ms/step - loss: 30.1888 - val_loss: 30.1335 - lr: 1.7150e-04\n","Epoch 37/100\n","71/71 [==============================] - ETA: 0s - loss: 30.0999\n","Epoch 37: val_loss improved from 29.77136 to 28.47393, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 47s 663ms/step - loss: 30.0999 - val_loss: 28.4739 - lr: 1.2005e-04\n","Epoch 38/100\n","71/71 [==============================] - ETA: 0s - loss: 29.6706\n","Epoch 38: val_loss did not improve from 28.47393\n","71/71 [==============================] - 45s 634ms/step - loss: 29.6706 - val_loss: 28.6967 - lr: 1.2005e-04\n","Epoch 39/100\n","71/71 [==============================] - ETA: 0s - loss: 29.0121\n","Epoch 39: val_loss improved from 28.47393 to 27.45353, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 47s 671ms/step - loss: 29.0121 - val_loss: 27.4535 - lr: 1.2005e-04\n","Epoch 40/100\n","71/71 [==============================] - ETA: 0s - loss: 29.7387\n","Epoch 40: val_loss did not improve from 27.45353\n","71/71 [==============================] - 45s 635ms/step - loss: 29.7387 - val_loss: 30.0514 - lr: 1.2005e-04\n","Epoch 41/100\n","71/71 [==============================] - ETA: 0s - loss: 28.3532\n","Epoch 41: val_loss did not improve from 27.45353\n","71/71 [==============================] - 44s 630ms/step - loss: 28.3532 - val_loss: 29.2706 - lr: 1.2005e-04\n","Epoch 42/100\n","71/71 [==============================] - ETA: 0s - loss: 29.3118\n","Epoch 42: val_loss did not improve from 27.45353\n","\n","Epoch 42: ReduceLROnPlateau reducing learning rate to 8.403499814448878e-05.\n","71/71 [==============================] - 45s 642ms/step - loss: 29.3118 - val_loss: 28.1262 - lr: 1.2005e-04\n","Epoch 43/100\n","71/71 [==============================] - ETA: 0s - loss: 28.4190\n","Epoch 43: val_loss did not improve from 27.45353\n","71/71 [==============================] - 45s 632ms/step - loss: 28.4190 - val_loss: 28.0367 - lr: 8.4035e-05\n","Epoch 44/100\n","71/71 [==============================] - ETA: 0s - loss: 28.4947\n","Epoch 44: val_loss did not improve from 27.45353\n","71/71 [==============================] - 44s 626ms/step - loss: 28.4947 - val_loss: 30.7522 - lr: 8.4035e-05\n","Epoch 45/100\n","71/71 [==============================] - ETA: 0s - loss: 28.1048\n","Epoch 45: val_loss improved from 27.45353 to 25.05722, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 47s 669ms/step - loss: 28.1048 - val_loss: 25.0572 - lr: 8.4035e-05\n","Epoch 46/100\n","71/71 [==============================] - ETA: 0s - loss: 28.1167\n","Epoch 46: val_loss did not improve from 25.05722\n","71/71 [==============================] - 45s 631ms/step - loss: 28.1167 - val_loss: 28.7592 - lr: 8.4035e-05\n","Epoch 47/100\n","71/71 [==============================] - ETA: 0s - loss: 28.2612\n","Epoch 47: val_loss did not improve from 25.05722\n","71/71 [==============================] - 44s 627ms/step - loss: 28.2612 - val_loss: 26.6752 - lr: 8.4035e-05\n","Epoch 48/100\n","71/71 [==============================] - ETA: 0s - loss: 27.6596\n","Epoch 48: val_loss did not improve from 25.05722\n","\n","Epoch 48: ReduceLROnPlateau reducing learning rate to 5.882449768250808e-05.\n","71/71 [==============================] - 44s 629ms/step - loss: 27.6596 - val_loss: 25.9033 - lr: 8.4035e-05\n","Epoch 49/100\n","71/71 [==============================] - ETA: 0s - loss: 27.7869\n","Epoch 49: val_loss did not improve from 25.05722\n","71/71 [==============================] - 45s 645ms/step - loss: 27.7869 - val_loss: 28.0142 - lr: 5.8824e-05\n","Epoch 50/100\n","71/71 [==============================] - ETA: 0s - loss: 26.9154\n","Epoch 50: val_loss did not improve from 25.05722\n","71/71 [==============================] - 45s 641ms/step - loss: 26.9154 - val_loss: 26.6290 - lr: 5.8824e-05\n","Epoch 51/100\n","71/71 [==============================] - ETA: 0s - loss: 27.8093\n","Epoch 51: val_loss did not improve from 25.05722\n","\n","Epoch 51: ReduceLROnPlateau reducing learning rate to 4.117714888707269e-05.\n","71/71 [==============================] - 44s 627ms/step - loss: 27.8093 - val_loss: 27.1394 - lr: 5.8824e-05\n","Epoch 52/100\n","71/71 [==============================] - ETA: 0s - loss: 26.7970\n","Epoch 52: val_loss did not improve from 25.05722\n","71/71 [==============================] - 44s 630ms/step - loss: 26.7970 - val_loss: 26.3057 - lr: 4.1177e-05\n","Epoch 53/100\n","71/71 [==============================] - ETA: 0s - loss: 26.5309\n","Epoch 53: val_loss did not improve from 25.05722\n","71/71 [==============================] - 44s 624ms/step - loss: 26.5309 - val_loss: 27.7961 - lr: 4.1177e-05\n","Epoch 54/100\n","71/71 [==============================] - ETA: 0s - loss: 26.4995\n","Epoch 54: val_loss did not improve from 25.05722\n","\n","Epoch 54: ReduceLROnPlateau reducing learning rate to 2.88240029476583e-05.\n","71/71 [==============================] - 44s 625ms/step - loss: 26.4995 - val_loss: 26.3559 - lr: 4.1177e-05\n","Epoch 55/100\n","71/71 [==============================] - ETA: 0s - loss: 27.0235\n","Epoch 55: val_loss did not improve from 25.05722\n","71/71 [==============================] - 45s 633ms/step - loss: 27.0235 - val_loss: 26.5576 - lr: 2.8824e-05\n","Epoch 56/100\n","71/71 [==============================] - ETA: 0s - loss: 26.5421\n","Epoch 56: val_loss did not improve from 25.05722\n","71/71 [==============================] - 44s 630ms/step - loss: 26.5421 - val_loss: 25.2801 - lr: 2.8824e-05\n","Epoch 57/100\n","71/71 [==============================] - ETA: 0s - loss: 26.4785\n","Epoch 57: val_loss did not improve from 25.05722\n","\n","Epoch 57: ReduceLROnPlateau reducing learning rate to 2.0176801808702293e-05.\n","71/71 [==============================] - 44s 628ms/step - loss: 26.4785 - val_loss: 25.5314 - lr: 2.8824e-05\n","Epoch 58/100\n","71/71 [==============================] - ETA: 0s - loss: 26.5890\n","Epoch 58: val_loss did not improve from 25.05722\n","71/71 [==============================] - 45s 641ms/step - loss: 26.5890 - val_loss: 27.6667 - lr: 2.0177e-05\n","Epoch 59/100\n","71/71 [==============================] - ETA: 0s - loss: 26.2539\n","Epoch 59: val_loss did not improve from 25.05722\n","71/71 [==============================] - 46s 652ms/step - loss: 26.2539 - val_loss: 26.7442 - lr: 2.0177e-05\n","Epoch 60/100\n","71/71 [==============================] - ETA: 0s - loss: 26.3737\n","Epoch 60: val_loss did not improve from 25.05722\n","\n","Epoch 60: ReduceLROnPlateau reducing learning rate to 1.4123761138762347e-05.\n","71/71 [==============================] - 46s 655ms/step - loss: 26.3737 - val_loss: 26.6368 - lr: 2.0177e-05\n","Epoch 61/100\n","71/71 [==============================] - ETA: 0s - loss: 25.2514\n","Epoch 61: val_loss improved from 25.05722 to 24.39224, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 49s 695ms/step - loss: 25.2514 - val_loss: 24.3922 - lr: 1.4124e-05\n","Epoch 62/100\n","71/71 [==============================] - ETA: 0s - loss: 26.8218\n","Epoch 62: val_loss did not improve from 24.39224\n","71/71 [==============================] - 46s 656ms/step - loss: 26.8218 - val_loss: 25.7308 - lr: 1.4124e-05\n","Epoch 63/100\n","71/71 [==============================] - ETA: 0s - loss: 25.1286\n","Epoch 63: val_loss did not improve from 24.39224\n","71/71 [==============================] - 45s 643ms/step - loss: 25.1286 - val_loss: 25.6564 - lr: 1.4124e-05\n","Epoch 64/100\n","71/71 [==============================] - ETA: 0s - loss: 26.2159\n","Epoch 64: val_loss did not improve from 24.39224\n","\n","Epoch 64: ReduceLROnPlateau reducing learning rate to 9.88663305179216e-06.\n","71/71 [==============================] - 44s 629ms/step - loss: 26.2159 - val_loss: 26.1357 - lr: 1.4124e-05\n","Epoch 65/100\n","71/71 [==============================] - ETA: 0s - loss: 25.2474\n","Epoch 65: val_loss did not improve from 24.39224\n","71/71 [==============================] - 45s 633ms/step - loss: 25.2474 - val_loss: 25.1659 - lr: 9.8866e-06\n","Epoch 66/100\n","71/71 [==============================] - ETA: 0s - loss: 26.3329\n","Epoch 66: val_loss did not improve from 24.39224\n","71/71 [==============================] - 45s 633ms/step - loss: 26.3329 - val_loss: 25.5994 - lr: 9.8866e-06\n","Epoch 67/100\n","71/71 [==============================] - ETA: 0s - loss: 26.1646\n","Epoch 67: val_loss did not improve from 24.39224\n","\n","Epoch 67: ReduceLROnPlateau reducing learning rate to 6.9206431362545114e-06.\n","71/71 [==============================] - 44s 618ms/step - loss: 26.1646 - val_loss: 25.0531 - lr: 9.8866e-06\n","Epoch 68/100\n","71/71 [==============================] - ETA: 0s - loss: 25.4447\n","Epoch 68: val_loss did not improve from 24.39224\n","71/71 [==============================] - 44s 630ms/step - loss: 25.4447 - val_loss: 24.8790 - lr: 6.9206e-06\n","Epoch 69/100\n","71/71 [==============================] - ETA: 0s - loss: 25.2923\n","Epoch 69: val_loss did not improve from 24.39224\n","71/71 [==============================] - 45s 640ms/step - loss: 25.2923 - val_loss: 25.2561 - lr: 6.9206e-06\n","Epoch 70/100\n","71/71 [==============================] - ETA: 0s - loss: 25.4329\n","Epoch 70: val_loss did not improve from 24.39224\n","\n","Epoch 70: ReduceLROnPlateau reducing learning rate to 4.844450131713529e-06.\n","71/71 [==============================] - 45s 643ms/step - loss: 25.4329 - val_loss: 25.6423 - lr: 6.9206e-06\n","Epoch 71/100\n","71/71 [==============================] - ETA: 0s - loss: 25.6446\n","Epoch 71: val_loss did not improve from 24.39224\n","71/71 [==============================] - 45s 642ms/step - loss: 25.6446 - val_loss: 26.0174 - lr: 4.8444e-06\n","Epoch 72/100\n","71/71 [==============================] - ETA: 0s - loss: 25.1096\n","Epoch 72: val_loss did not improve from 24.39224\n","71/71 [==============================] - 45s 645ms/step - loss: 25.1096 - val_loss: 24.8443 - lr: 4.8444e-06\n","Epoch 73/100\n","71/71 [==============================] - ETA: 0s - loss: 25.3128\n","Epoch 73: val_loss did not improve from 24.39224\n","\n","Epoch 73: ReduceLROnPlateau reducing learning rate to 3.3911149330378974e-06.\n","71/71 [==============================] - 45s 641ms/step - loss: 25.3128 - val_loss: 26.1217 - lr: 4.8444e-06\n","Epoch 74/100\n","71/71 [==============================] - ETA: 0s - loss: 25.3354\n","Epoch 74: val_loss did not improve from 24.39224\n","71/71 [==============================] - 45s 638ms/step - loss: 25.3354 - val_loss: 25.1479 - lr: 3.3911e-06\n","Epoch 75/100\n","71/71 [==============================] - ETA: 0s - loss: 25.5662\n","Epoch 75: val_loss did not improve from 24.39224\n","71/71 [==============================] - 45s 633ms/step - loss: 25.5662 - val_loss: 26.2022 - lr: 3.3911e-06\n","Epoch 76/100\n","71/71 [==============================] - ETA: 0s - loss: 25.3981\n","Epoch 76: val_loss did not improve from 24.39224\n","\n","Epoch 76: ReduceLROnPlateau reducing learning rate to 2.3737804212942136e-06.\n","71/71 [==============================] - 44s 620ms/step - loss: 25.3981 - val_loss: 24.9721 - lr: 3.3911e-06\n","Epoch 77/100\n","71/71 [==============================] - ETA: 0s - loss: 25.1601\n","Epoch 77: val_loss did not improve from 24.39224\n","71/71 [==============================] - 43s 613ms/step - loss: 25.1601 - val_loss: 27.0601 - lr: 2.3738e-06\n","Epoch 78/100\n","71/71 [==============================] - ETA: 0s - loss: 24.8018\n","Epoch 78: val_loss did not improve from 24.39224\n","71/71 [==============================] - 44s 623ms/step - loss: 24.8018 - val_loss: 24.3956 - lr: 2.3738e-06\n","Epoch 79/100\n","71/71 [==============================] - ETA: 0s - loss: 25.6085\n","Epoch 79: val_loss did not improve from 24.39224\n","\n","Epoch 79: ReduceLROnPlateau reducing learning rate to 1.6616463426544213e-06.\n","71/71 [==============================] - 44s 623ms/step - loss: 25.6085 - val_loss: 25.9122 - lr: 2.3738e-06\n","Epoch 80/100\n","71/71 [==============================] - ETA: 0s - loss: 26.0621\n","Epoch 80: val_loss did not improve from 24.39224\n","71/71 [==============================] - 43s 612ms/step - loss: 26.0621 - val_loss: 24.7800 - lr: 1.6616e-06\n","Epoch 81/100\n","71/71 [==============================] - ETA: 0s - loss: 24.9651\n","Epoch 81: val_loss improved from 24.39224 to 24.34393, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 47s 664ms/step - loss: 24.9651 - val_loss: 24.3439 - lr: 1.6616e-06\n","Epoch 82/100\n","71/71 [==============================] - ETA: 0s - loss: 25.7309\n","Epoch 82: val_loss did not improve from 24.34393\n","71/71 [==============================] - 44s 623ms/step - loss: 25.7309 - val_loss: 24.3997 - lr: 1.6616e-06\n","Epoch 83/100\n","71/71 [==============================] - ETA: 0s - loss: 24.8360\n","Epoch 83: val_loss did not improve from 24.34393\n","71/71 [==============================] - 44s 622ms/step - loss: 24.8360 - val_loss: 27.0544 - lr: 1.6616e-06\n","Epoch 84/100\n","71/71 [==============================] - ETA: 0s - loss: 25.3176\n","Epoch 84: val_loss improved from 24.34393 to 24.23086, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 46s 657ms/step - loss: 25.3176 - val_loss: 24.2309 - lr: 1.6616e-06\n","Epoch 85/100\n","71/71 [==============================] - ETA: 0s - loss: 25.3464\n","Epoch 85: val_loss did not improve from 24.23086\n","71/71 [==============================] - 44s 622ms/step - loss: 25.3464 - val_loss: 25.3596 - lr: 1.6616e-06\n","Epoch 86/100\n","71/71 [==============================] - ETA: 0s - loss: 25.1632\n","Epoch 86: val_loss did not improve from 24.23086\n","71/71 [==============================] - 44s 620ms/step - loss: 25.1632 - val_loss: 26.8102 - lr: 1.6616e-06\n","Epoch 87/100\n","71/71 [==============================] - ETA: 0s - loss: 25.2611\n","Epoch 87: val_loss did not improve from 24.23086\n","\n","Epoch 87: ReduceLROnPlateau reducing learning rate to 1.1631524557742522e-06.\n","71/71 [==============================] - 43s 615ms/step - loss: 25.2611 - val_loss: 25.8741 - lr: 1.6616e-06\n","Epoch 88/100\n","71/71 [==============================] - ETA: 0s - loss: 24.9416\n","Epoch 88: val_loss did not improve from 24.23086\n","71/71 [==============================] - 43s 615ms/step - loss: 24.9416 - val_loss: 24.6415 - lr: 1.1632e-06\n","Epoch 89/100\n","71/71 [==============================] - ETA: 0s - loss: 25.5030\n","Epoch 89: val_loss did not improve from 24.23086\n","71/71 [==============================] - 44s 617ms/step - loss: 25.5030 - val_loss: 26.5168 - lr: 1.1632e-06\n","Epoch 90/100\n","71/71 [==============================] - ETA: 0s - loss: 25.4471\n","Epoch 90: val_loss improved from 24.23086 to 24.17194, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 46s 649ms/step - loss: 25.4471 - val_loss: 24.1719 - lr: 1.1632e-06\n","Epoch 91/100\n","71/71 [==============================] - ETA: 0s - loss: 25.7977\n","Epoch 91: val_loss did not improve from 24.17194\n","71/71 [==============================] - 43s 614ms/step - loss: 25.7977 - val_loss: 24.6051 - lr: 1.1632e-06\n","Epoch 92/100\n","71/71 [==============================] - ETA: 0s - loss: 24.7700\n","Epoch 92: val_loss did not improve from 24.17194\n","71/71 [==============================] - 44s 621ms/step - loss: 24.7700 - val_loss: 27.5367 - lr: 1.1632e-06\n","Epoch 93/100\n","71/71 [==============================] - ETA: 0s - loss: 25.8499\n","Epoch 93: val_loss did not improve from 24.17194\n","\n","Epoch 93: ReduceLROnPlateau reducing learning rate to 8.142067031258193e-07.\n","71/71 [==============================] - 43s 614ms/step - loss: 25.8499 - val_loss: 24.4030 - lr: 1.1632e-06\n","Epoch 94/100\n","71/71 [==============================] - ETA: 0s - loss: 24.6609\n","Epoch 94: val_loss did not improve from 24.17194\n","71/71 [==============================] - 44s 626ms/step - loss: 24.6609 - val_loss: 24.9442 - lr: 8.1421e-07\n","Epoch 95/100\n","71/71 [==============================] - ETA: 0s - loss: 26.0877\n","Epoch 95: val_loss did not improve from 24.17194\n","71/71 [==============================] - 45s 638ms/step - loss: 26.0877 - val_loss: 24.7848 - lr: 8.1421e-07\n","Epoch 96/100\n","71/71 [==============================] - ETA: 0s - loss: 25.0661\n","Epoch 96: val_loss did not improve from 24.17194\n","\n","Epoch 96: ReduceLROnPlateau reducing learning rate to 5.699447001461521e-07.\n","71/71 [==============================] - 47s 669ms/step - loss: 25.0661 - val_loss: 24.9332 - lr: 8.1421e-07\n","Epoch 97/100\n","71/71 [==============================] - ETA: 0s - loss: 24.8764\n","Epoch 97: val_loss did not improve from 24.17194\n","71/71 [==============================] - 44s 623ms/step - loss: 24.8764 - val_loss: 24.8215 - lr: 5.6994e-07\n","Epoch 98/100\n","71/71 [==============================] - ETA: 0s - loss: 25.3608\n","Epoch 98: val_loss did not improve from 24.17194\n","71/71 [==============================] - 44s 622ms/step - loss: 25.3608 - val_loss: 28.2032 - lr: 5.6994e-07\n","Epoch 99/100\n","71/71 [==============================] - ETA: 0s - loss: 24.7461\n","Epoch 99: val_loss did not improve from 24.17194\n","\n","Epoch 99: ReduceLROnPlateau reducing learning rate to 3.9896128214422786e-07.\n","71/71 [==============================] - 44s 620ms/step - loss: 24.7461 - val_loss: 24.3054 - lr: 5.6994e-07\n","Epoch 100/100\n","71/71 [==============================] - ETA: 0s - loss: 25.7288\n","Epoch 100: val_loss did not improve from 24.17194\n","71/71 [==============================] - 46s 655ms/step - loss: 25.7288 - val_loss: 24.5194 - lr: 3.9896e-07\n"]}],"source":["# путь и колбэк для сохранения истории обучения\n","\n","history_path = '/content/model_history_log2.csv'\n","csv_logger = CSVLogger(history_path, append=True)\n","\n","# уменьшение lr\n","reduceLROnPlateau = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=3, verbose=1)\n","\n","# сохранение весов\n","model_checkpoint = ModelCheckpoint(weights_path, monitor='val_loss', save_best_only=True, verbose=1)\n","\n","# Запускаем процесс обучения на 100 эпохах\n","history = model_YOLO.fit(data_generator(annot_list[:num_train], batch_size, anchors, input_shape),\n","                         steps_per_epoch = max (1, num_train//batch_size),\n","                         validation_data = data_generator(annot_list[num_train:],\n","                                                          batch_size,\n","                                                          anchors,\n","                                                          input_shape),\n","                         validation_steps = max (1, num_val//batch_size),\n","                         epochs = 100,\n","                         verbose = 1,\n","                         initial_epoch = 0,\n","                         callbacks=[model_checkpoint,\n","                                    reduceLROnPlateau,\n","                                    csv_logger])"]},{"cell_type":"markdown","metadata":{"id":"8bFioWL4J9rG"},"source":["Для достижения лучшего результата, дообучим сеть с более низким LR."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ic8UX8XtSre8"},"outputs":[],"source":["model_YOLO.load_weights(weights_path) # дообучим сеть, подгрузив последние веса"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2256627,"status":"ok","timestamp":1646350626145,"user":{"displayName":"Университет искусственного интеллекта","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKwCtaFiq_5mTGvq9QYM1-sEnTJI6yV-ouy66c=s64","userId":"12454839568076823986"},"user_tz":-180},"id":"2HQ3t_xgSZlH","outputId":"6855dd59-0bb6-4063-c7f5-6d13e8903fa3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","71/71 [==============================] - ETA: 0s - loss: 25.3423\n","Epoch 1: val_loss improved from inf to 25.42648, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 65s 720ms/step - loss: 25.3423 - val_loss: 25.4265 - lr: 1.0000e-05\n","Epoch 2/50\n","71/71 [==============================] - ETA: 0s - loss: 24.8562\n","Epoch 2: val_loss improved from 25.42648 to 24.87281, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 46s 659ms/step - loss: 24.8562 - val_loss: 24.8728 - lr: 1.0000e-05\n","Epoch 3/50\n","71/71 [==============================] - ETA: 0s - loss: 25.0252\n","Epoch 3: val_loss did not improve from 24.87281\n","71/71 [==============================] - 45s 645ms/step - loss: 25.0252 - val_loss: 25.2307 - lr: 1.0000e-05\n","Epoch 4/50\n","71/71 [==============================] - ETA: 0s - loss: 24.8519\n","Epoch 4: val_loss improved from 24.87281 to 24.36478, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 47s 666ms/step - loss: 24.8519 - val_loss: 24.3648 - lr: 1.0000e-05\n","Epoch 5/50\n","71/71 [==============================] - ETA: 0s - loss: 24.7710\n","Epoch 5: val_loss did not improve from 24.36478\n","71/71 [==============================] - 44s 629ms/step - loss: 24.7710 - val_loss: 24.7147 - lr: 1.0000e-05\n","Epoch 6/50\n","71/71 [==============================] - ETA: 0s - loss: 24.6109\n","Epoch 6: val_loss improved from 24.36478 to 24.30212, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 46s 650ms/step - loss: 24.6109 - val_loss: 24.3021 - lr: 1.0000e-05\n","Epoch 7/50\n","71/71 [==============================] - ETA: 0s - loss: 24.8557\n","Epoch 7: val_loss did not improve from 24.30212\n","71/71 [==============================] - 44s 631ms/step - loss: 24.8557 - val_loss: 24.3971 - lr: 1.0000e-05\n","Epoch 8/50\n","71/71 [==============================] - ETA: 0s - loss: 24.3887\n","Epoch 8: val_loss did not improve from 24.30212\n","71/71 [==============================] - 45s 637ms/step - loss: 24.3887 - val_loss: 24.4179 - lr: 1.0000e-05\n","Epoch 9/50\n","71/71 [==============================] - ETA: 0s - loss: 24.3519\n","Epoch 9: val_loss improved from 24.30212 to 23.22628, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 49s 690ms/step - loss: 24.3519 - val_loss: 23.2263 - lr: 1.0000e-05\n","Epoch 10/50\n","71/71 [==============================] - ETA: 0s - loss: 24.4219\n","Epoch 10: val_loss did not improve from 23.22628\n","71/71 [==============================] - 47s 663ms/step - loss: 24.4219 - val_loss: 24.3099 - lr: 1.0000e-05\n","Epoch 11/50\n","71/71 [==============================] - ETA: 0s - loss: 24.1207\n","Epoch 11: val_loss did not improve from 23.22628\n","71/71 [==============================] - 45s 645ms/step - loss: 24.1207 - val_loss: 24.4994 - lr: 1.0000e-05\n","Epoch 12/50\n","71/71 [==============================] - ETA: 0s - loss: 24.0699\n","Epoch 12: val_loss did not improve from 23.22628\n","\n","Epoch 12: ReduceLROnPlateau reducing learning rate to 8.09999979537679e-06.\n","71/71 [==============================] - 45s 641ms/step - loss: 24.0699 - val_loss: 23.8793 - lr: 1.0000e-05\n","Epoch 13/50\n","71/71 [==============================] - ETA: 0s - loss: 24.2760\n","Epoch 13: val_loss did not improve from 23.22628\n","71/71 [==============================] - 46s 648ms/step - loss: 24.2760 - val_loss: 24.6744 - lr: 8.1000e-06\n","Epoch 14/50\n","71/71 [==============================] - ETA: 0s - loss: 24.2336\n","Epoch 14: val_loss did not improve from 23.22628\n","71/71 [==============================] - 44s 618ms/step - loss: 24.2336 - val_loss: 23.8393 - lr: 8.1000e-06\n","Epoch 15/50\n","71/71 [==============================] - ETA: 0s - loss: 23.7703\n","Epoch 15: val_loss did not improve from 23.22628\n","\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 6.560999863722828e-06.\n","71/71 [==============================] - 44s 617ms/step - loss: 23.7703 - val_loss: 25.0428 - lr: 8.1000e-06\n","Epoch 16/50\n","71/71 [==============================] - ETA: 0s - loss: 23.7689\n","Epoch 16: val_loss did not improve from 23.22628\n","71/71 [==============================] - 44s 619ms/step - loss: 23.7689 - val_loss: 25.1165 - lr: 6.5610e-06\n","Epoch 17/50\n","71/71 [==============================] - ETA: 0s - loss: 23.5267\n","Epoch 17: val_loss did not improve from 23.22628\n","71/71 [==============================] - 43s 611ms/step - loss: 23.5267 - val_loss: 24.3482 - lr: 6.5610e-06\n","Epoch 18/50\n","71/71 [==============================] - ETA: 0s - loss: 23.6949\n","Epoch 18: val_loss did not improve from 23.22628\n","\n","Epoch 18: ReduceLROnPlateau reducing learning rate to 5.314409786478791e-06.\n","71/71 [==============================] - 44s 617ms/step - loss: 23.6949 - val_loss: 24.3108 - lr: 6.5610e-06\n","Epoch 19/50\n","71/71 [==============================] - ETA: 0s - loss: 23.7222\n","Epoch 19: val_loss did not improve from 23.22628\n","71/71 [==============================] - 43s 610ms/step - loss: 23.7222 - val_loss: 24.5680 - lr: 5.3144e-06\n","Epoch 20/50\n","71/71 [==============================] - ETA: 0s - loss: 23.8993\n","Epoch 20: val_loss did not improve from 23.22628\n","71/71 [==============================] - 43s 606ms/step - loss: 23.8993 - val_loss: 24.8232 - lr: 5.3144e-06\n","Epoch 21/50\n","71/71 [==============================] - ETA: 0s - loss: 23.0767\n","Epoch 21: val_loss did not improve from 23.22628\n","\n","Epoch 21: ReduceLROnPlateau reducing learning rate to 4.3046720338679734e-06.\n","71/71 [==============================] - 43s 607ms/step - loss: 23.0767 - val_loss: 23.9523 - lr: 5.3144e-06\n","Epoch 22/50\n","71/71 [==============================] - ETA: 0s - loss: 23.8380\n","Epoch 22: val_loss did not improve from 23.22628\n","71/71 [==============================] - 43s 614ms/step - loss: 23.8380 - val_loss: 23.5261 - lr: 4.3047e-06\n","Epoch 23/50\n","71/71 [==============================] - ETA: 0s - loss: 23.4000\n","Epoch 23: val_loss did not improve from 23.22628\n","71/71 [==============================] - 43s 612ms/step - loss: 23.4000 - val_loss: 24.6664 - lr: 4.3047e-06\n","Epoch 24/50\n","71/71 [==============================] - ETA: 0s - loss: 23.6348\n","Epoch 24: val_loss did not improve from 23.22628\n","\n","Epoch 24: ReduceLROnPlateau reducing learning rate to 3.4867843805841405e-06.\n","71/71 [==============================] - 43s 614ms/step - loss: 23.6348 - val_loss: 23.9102 - lr: 4.3047e-06\n","Epoch 25/50\n","71/71 [==============================] - ETA: 0s - loss: 23.6142\n","Epoch 25: val_loss did not improve from 23.22628\n","71/71 [==============================] - 43s 613ms/step - loss: 23.6142 - val_loss: 23.7800 - lr: 3.4868e-06\n","Epoch 26/50\n","71/71 [==============================] - ETA: 0s - loss: 23.1229\n","Epoch 26: val_loss did not improve from 23.22628\n","71/71 [==============================] - 44s 623ms/step - loss: 23.1229 - val_loss: 24.0846 - lr: 3.4868e-06\n","Epoch 27/50\n","71/71 [==============================] - ETA: 0s - loss: 23.5369\n","Epoch 27: val_loss did not improve from 23.22628\n","\n","Epoch 27: ReduceLROnPlateau reducing learning rate to 2.824295370373875e-06.\n","71/71 [==============================] - 44s 624ms/step - loss: 23.5369 - val_loss: 24.0336 - lr: 3.4868e-06\n","Epoch 28/50\n","71/71 [==============================] - ETA: 0s - loss: 23.5578\n","Epoch 28: val_loss did not improve from 23.22628\n","71/71 [==============================] - 45s 632ms/step - loss: 23.5578 - val_loss: 23.3688 - lr: 2.8243e-06\n","Epoch 29/50\n","71/71 [==============================] - ETA: 0s - loss: 23.7586\n","Epoch 29: val_loss did not improve from 23.22628\n","71/71 [==============================] - 44s 627ms/step - loss: 23.7586 - val_loss: 23.5489 - lr: 2.8243e-06\n","Epoch 30/50\n","71/71 [==============================] - ETA: 0s - loss: 23.1145\n","Epoch 30: val_loss did not improve from 23.22628\n","\n","Epoch 30: ReduceLROnPlateau reducing learning rate to 2.287679176333768e-06.\n","71/71 [==============================] - 44s 626ms/step - loss: 23.1145 - val_loss: 23.3396 - lr: 2.8243e-06\n","Epoch 31/50\n","71/71 [==============================] - ETA: 0s - loss: 23.3229\n","Epoch 31: val_loss improved from 23.22628 to 21.91251, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 48s 684ms/step - loss: 23.3229 - val_loss: 21.9125 - lr: 2.2877e-06\n","Epoch 32/50\n","71/71 [==============================] - ETA: 0s - loss: 22.7869\n","Epoch 32: val_loss did not improve from 21.91251\n","71/71 [==============================] - 45s 644ms/step - loss: 22.7869 - val_loss: 24.1556 - lr: 2.2877e-06\n","Epoch 33/50\n","71/71 [==============================] - ETA: 0s - loss: 23.3581\n","Epoch 33: val_loss did not improve from 21.91251\n","71/71 [==============================] - 47s 674ms/step - loss: 23.3581 - val_loss: 22.5785 - lr: 2.2877e-06\n","Epoch 34/50\n","71/71 [==============================] - ETA: 0s - loss: 23.2437\n","Epoch 34: val_loss did not improve from 21.91251\n","\n","Epoch 34: ReduceLROnPlateau reducing learning rate to 1.8530200554778277e-06.\n","71/71 [==============================] - 45s 639ms/step - loss: 23.2437 - val_loss: 26.8231 - lr: 2.2877e-06\n","Epoch 35/50\n","71/71 [==============================] - ETA: 0s - loss: 22.9195\n","Epoch 35: val_loss improved from 21.91251 to 20.46538, saving model to /content/yolo_chess.h5\n","71/71 [==============================] - 47s 665ms/step - loss: 22.9195 - val_loss: 20.4654 - lr: 1.8530e-06\n","Epoch 36/50\n","71/71 [==============================] - ETA: 0s - loss: 23.4795\n","Epoch 36: val_loss did not improve from 20.46538\n","71/71 [==============================] - 47s 670ms/step - loss: 23.4795 - val_loss: 25.0810 - lr: 1.8530e-06\n","Epoch 37/50\n","71/71 [==============================] - ETA: 0s - loss: 23.1950\n","Epoch 37: val_loss did not improve from 20.46538\n","71/71 [==============================] - 47s 662ms/step - loss: 23.1950 - val_loss: 22.9340 - lr: 1.8530e-06\n","Epoch 38/50\n","71/71 [==============================] - ETA: 0s - loss: 22.9407\n","Epoch 38: val_loss did not improve from 20.46538\n","\n","Epoch 38: ReduceLROnPlateau reducing learning rate to 1.5009462651960349e-06.\n","71/71 [==============================] - 46s 647ms/step - loss: 22.9407 - val_loss: 23.2291 - lr: 1.8530e-06\n","Epoch 39/50\n","71/71 [==============================] - ETA: 0s - loss: 23.2063\n","Epoch 39: val_loss did not improve from 20.46538\n","71/71 [==============================] - 43s 617ms/step - loss: 23.2063 - val_loss: 23.4255 - lr: 1.5009e-06\n","Epoch 40/50\n","71/71 [==============================] - ETA: 0s - loss: 23.5020\n","Epoch 40: val_loss did not improve from 20.46538\n","71/71 [==============================] - 44s 622ms/step - loss: 23.5020 - val_loss: 22.0961 - lr: 1.5009e-06\n","Epoch 41/50\n","71/71 [==============================] - ETA: 0s - loss: 22.5366\n","Epoch 41: val_loss did not improve from 20.46538\n","\n","Epoch 41: ReduceLROnPlateau reducing learning rate to 1.2157664775713785e-06.\n","71/71 [==============================] - 44s 618ms/step - loss: 22.5366 - val_loss: 25.3961 - lr: 1.5009e-06\n","Epoch 42/50\n","71/71 [==============================] - ETA: 0s - loss: 22.8772\n","Epoch 42: val_loss did not improve from 20.46538\n","71/71 [==============================] - 44s 624ms/step - loss: 22.8772 - val_loss: 22.7994 - lr: 1.2158e-06\n","Epoch 43/50\n","71/71 [==============================] - ETA: 0s - loss: 23.1219\n","Epoch 43: val_loss did not improve from 20.46538\n","71/71 [==============================] - 45s 631ms/step - loss: 23.1219 - val_loss: 23.8522 - lr: 1.2158e-06\n","Epoch 44/50\n","71/71 [==============================] - ETA: 0s - loss: 22.9507\n","Epoch 44: val_loss did not improve from 20.46538\n","\n","Epoch 44: ReduceLROnPlateau reducing learning rate to 9.847708440702264e-07.\n","71/71 [==============================] - 45s 632ms/step - loss: 22.9507 - val_loss: 22.9394 - lr: 1.2158e-06\n","Epoch 45/50\n","71/71 [==============================] - ETA: 0s - loss: 23.2184\n","Epoch 45: val_loss did not improve from 20.46538\n","71/71 [==============================] - 44s 628ms/step - loss: 23.2184 - val_loss: 23.6861 - lr: 9.8477e-07\n","Epoch 46/50\n","71/71 [==============================] - ETA: 0s - loss: 22.9788\n","Epoch 46: val_loss did not improve from 20.46538\n","71/71 [==============================] - 44s 623ms/step - loss: 22.9788 - val_loss: 24.6292 - lr: 9.8477e-07\n","Epoch 47/50\n","71/71 [==============================] - ETA: 0s - loss: 22.9214\n","Epoch 47: val_loss did not improve from 20.46538\n","\n","Epoch 47: ReduceLROnPlateau reducing learning rate to 7.976643883012003e-07.\n","71/71 [==============================] - 44s 628ms/step - loss: 22.9214 - val_loss: 23.4735 - lr: 9.8477e-07\n","Epoch 48/50\n","71/71 [==============================] - ETA: 0s - loss: 22.7697\n","Epoch 48: val_loss did not improve from 20.46538\n","71/71 [==============================] - 44s 622ms/step - loss: 22.7697 - val_loss: 22.2278 - lr: 7.9766e-07\n","Epoch 49/50\n","71/71 [==============================] - ETA: 0s - loss: 22.7271\n","Epoch 49: val_loss did not improve from 20.46538\n","71/71 [==============================] - 44s 623ms/step - loss: 22.7271 - val_loss: 22.9553 - lr: 7.9766e-07\n","Epoch 50/50\n","71/71 [==============================] - ETA: 0s - loss: 23.7954\n","Epoch 50: val_loss did not improve from 20.46538\n","\n","Epoch 50: ReduceLROnPlateau reducing learning rate to 6.461081397901581e-07.\n","71/71 [==============================] - 44s 620ms/step - loss: 23.7954 - val_loss: 23.9662 - lr: 7.9766e-07\n"]}],"source":["# Уменьшаем lr\n","optimizer = Adam(learning_rate=1e-5)\n","\n","model_YOLO.compile(optimizer=optimizer,\n","                   loss={'yolo_loss': lambda y_true, y_pred: y_pred})\n","\n","history_path_2 = '/content/model_history_log2_2.csv'\n","csv_logger = CSVLogger(history_path_2, append=True)\n","\n","# уменьшение lr\n","reduceLROnPlateau = ReduceLROnPlateau(monitor='val_loss', factor=0.81, patience=3, verbose=1)\n","\n","# сохранение весов\n","model_checkpoint = ModelCheckpoint(weights_path, monitor='val_loss', save_best_only=True, verbose=1)\n","\n","# Запускаем процесс обучения на 100 эпохах\n","history = model_YOLO.fit(data_generator(annot_list[:num_train], batch_size, anchors, input_shape),\n","                         steps_per_epoch = max (1, num_train//batch_size),\n","                         validation_data = data_generator(annot_list[num_train:],\n","                                                          batch_size,\n","                                                          anchors,\n","                                                          input_shape),\n","                         validation_steps = max (1, num_val//batch_size),\n","                         epochs = 50,\n","                         verbose = 1,\n","                         initial_epoch = 0,\n","                         callbacks=[model_checkpoint,\n","                                    reduceLROnPlateau,\n","                                    csv_logger])"]},{"cell_type":"markdown","metadata":{"id":"RtQMZQWuFR0U"},"source":["## Тестирование сети"]},{"cell_type":"markdown","metadata":{"id":"fe9FyXfzKHY_"},"source":["Создадим класс для интерпретации bounding boxes. Объекты этого класса будут хранить всю необходимую информацию о bounding boxes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eGVkHxzn3gIb"},"outputs":[],"source":["class BoundBox:\n","\n","    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n","        self.xmin = xmin\n","        self.ymin = ymin\n","        self.xmax = xmax\n","        self.ymax = ymax\n","        self.objness = objness\n","        self.classes = classes\n","        self.label = -1\n","        self.score = -1\n","\n","    # функция для получения значения метки\n","    def get_label(self):\n","        if self.label == -1:\n","            self.label = np.argmax(self.classes)\n","\n","        return self.label\n","\n","    # получение вероятности текущей метки\n","    def get_score(self):\n","        if self.score == -1:\n","            self.score = self.classes[self.get_label()]\n","\n","        return self.score"]},{"cell_type":"markdown","metadata":{"id":"P1hWePT7KapY"},"source":["Функция расчёта сигмоиды. Понадобится для декодирования выхода сети."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"euNsL-oYKbZ3"},"outputs":[],"source":["def _sigmoid(x):\n","\n","    return 1. / (1. + np.exp(-x))"]},{"cell_type":"markdown","metadata":{"id":"dKGsDAD8KuyZ"},"source":["Функция декодирования предсказаний сети и получения реальной информации о предсказанных bboxes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4SvPV3mUUQJy"},"outputs":[],"source":["def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n","\n","    ''' Функция декодирования выхода сети\n","        Args:\n","            netout -\n","            anchors -\n","            obj_thresh -\n","            net_h -\n","            net_w -\n","\n","        Return:\n","            boxes -\n","        '''\n","\n","    grid_h, grid_w = netout.shape[:2]\n","    nb_box = 3\n","    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n","    nb_class = netout.shape[-1] - 5\n","    boxes = []\n","    netout[..., :2]  = _sigmoid(netout[..., :2])\n","    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n","    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n","    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n","\n","    for i in range(grid_h*grid_w):\n","        row = i / grid_w\n","        col = i % grid_w\n","\n","        for b in range(nb_box):\n","            # 5-й элемент объектность (4-й если считать с нуля). Получаем вероятность нахождения объекта\n","            objectness = netout[int(row)][int(col)][b][4]\n","\n","            if(objectness.all() <= obj_thresh): continue\n","            # первые 4 элемента - это x, y, w и h\n","            x, y, w, h = netout[int(row)][int(col)][b][:4]\n","            x = (col + x) / grid_w # центральное подожение рамки относительно ширины сетки (якорного поля)\n","            y = (row + y) / grid_h # центральное подожение рамки относительно высоты сетки (якорного поля)\n","            w = anchors[2 * b + 0] * np.exp(w) / net_w # ширина рамки bbox\n","            h = anchors[2 * b + 1] * np.exp(h) / net_h # высота рамки bbox\n","\n","            # последине элементы - вероятности классов текущего объекта\n","            classes = netout[int(row)][col][b][5:]\n","            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n","            boxes.append(box)\n","\n","    return boxes"]},{"cell_type":"markdown","metadata":{"id":"j9j3gn5ALJWv"},"source":["Функция, приводящая Bounding Boxes к реальным значениям."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"71zUHl0QLJ1Q"},"outputs":[],"source":["def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n","\n","    ''' Функция, приводящая Bounding Boxes к реальным значениям\n","        Args:\n","            boxes -\n","            image_h -\n","            image_w -\n","            net_h -\n","            net_w -\n","\n","        Return:\n","            -\n","        '''\n","\n","    new_w, new_h = net_w, net_h\n","\n","    for i in range(len(boxes)):\n","        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n","        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n","        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n","        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n","        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n","        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)"]},{"cell_type":"markdown","metadata":{"id":"DCYaOe5DLVuS"},"source":["Функция подсчета метрики IOU."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"65kvS7zALWH3"},"outputs":[],"source":["def _interval_overlap(interval_a, interval_b):\n","\n","    ''' Функция пересечения интервалов\n","        Args:\n","            interval_a -\n","            interval_b -\n","\n","        Return:\n","            -\n","        '''\n","\n","    x1, x2 = interval_a # Получаем нижнюю и верхнюю границу 1-го интервала\n","    x3, x4 = interval_b # Получаем нижнюю и верхнюю границу 2-го интервала\n","\n","    if x3 < x1: # если начало 2-го интервала меньше начала 1-го\n","\n","        if x4 < x1: # Если и конец 2-го интервала меньше начала 1-го\n","            return 0 # Интервалы не пересекаются, возвращаем 0\n","        else:\n","            return min(x2,x4) - x1 # В ином случае, возвращаем пересечение\n","\n","    else: # Аналогичный обратный случай\n","\n","        if x2 < x3:\n","            return 0\n","        else:\n","            return min(x2,x4) - x3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z0cQ2BguVSAv"},"outputs":[],"source":["def intersectionOverUnion(box1, box2):\n","\n","    ''' Функция ...\n","        Args:\n","            box1 -\n","            box2 -\n","\n","        Return:\n","            -\n","        '''\n","\n","    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax]) # Пересечение по ширине\n","    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax]) # Пересечение по высоте\n","    intersect_area = intersect_w * intersect_h # Суммарное пересечение области\n","\n","    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin # Ширина и высота первого bbox\n","    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin # Ширина и высота второго bbox\n","\n","    union_area = w1*h1 + w2*h2 - intersect_area # Вычисляем объединение двух bboxes\n","\n","    return float(intersect_area) / union_area # Находим IoU как соотношение пересечения и объединения"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N-0Eq6ZsNb1J"},"outputs":[],"source":["def do_nms(boxes, nms_thresh):\n","\n","    ''' Функция подавления лишних BBox с помощью Non Maximum Suppression\n","        Args:\n","            boxes -\n","            nms_thresh -\n","\n","        Return:\n","            -\n","        '''\n","\n","    if len(boxes) > 0:\n","        nb_class = len(boxes[0].classes)\n","    else:\n","        return\n","\n","    for c in range(nb_class):\n","        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n","        for i in range(len(sorted_indices)):\n","            index_i = sorted_indices[i]\n","            if boxes[index_i].classes[c] == 0: continue\n","            for j in range(i+1, len(sorted_indices)):\n","                index_j = sorted_indices[j]\n","                if intersectionOverUnion(boxes[index_i], boxes[index_j]) >= nms_thresh:\n","                    boxes[index_j].classes[c] = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35pprD8XNplJ"},"outputs":[],"source":["def get_boxes(boxes, labels, thresh):\n","\n","    ''' Функция получения результатов, вероятность которых выше заданного порогового значения\n","        Args:\n","            boxes -\n","            labels -\n","            thresh -\n","\n","        Return:\n","            - v_boxes, v_labels, v_scores списки, содержащие подходящие боксы\n","        '''\n","    v_boxes, v_labels, v_scores = list(), list(), list()\n","\n","    #проходим в цикле по каждой рамке\n","    for box in boxes:\n","\n","        # проходим в цикле по каждой вероятной метке класса\n","        for i in range(len(labels)):\n","\n","            # проверяем превышает ли вероятность метки класса пороговое значение threshold\n","            if box.classes[i] > thresh:\n","\n","                v_boxes.append(box)\n","                v_labels.append(labels[i])\n","                v_scores.append(box.classes[i]*100)\n","                # для одной рамки может быть назначено несколько классов\n","\n","    return v_boxes, v_labels, v_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zwuoliQTN4wA"},"outputs":[],"source":["def draw_boxes(filename, v_boxes, v_labels, v_scores):\n","\n","    ''' Функция отрисовки результатов\n","        Args:\n","            filename -\n","            v_boxes -\n","            v_labels -\n","            v_scores -\n","\n","        Return:\n","            -\n","        '''\n","\n","    # загружаем изображение\n","    data = plt.imread(filename)\n","    plt.figure(figsize=(10,10))\n","\n","    # строим изображение\n","    plt.imshow(data)\n","    plt.axis('off')\n","\n","    # получаем значения осей для рисования рамок\n","    ax = plt.gca()\n","\n","    # рисуем каждую рамку (bbox)\n","    for i in range(len(v_boxes)):\n","\n","        box = v_boxes[i]\n","\n","        # получаем координаты\n","        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n","\n","        # считаем ширину и высоту рамки\n","        width, height = x2 - x1, y2 - y1\n","\n","        # создаем рамку\n","        rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n","\n","        # накладываем рамку на изображение\n","        ax.add_patch(rect)\n","\n","        # выводим текст и значения вероятностей в левом верхнем углу\n","        label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n","        plt.text(x1, y1, label, color='red')\n","\n","    # выводим все изображение\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FerE5l-U7eRg"},"outputs":[],"source":["def load_image_pixels(filename, shape):\n","\n","    ''' Функция отрисовки результатов\n","        Args:\n","            filename -\n","            shape -\n","\n","        Return:\n","            - img, width, height - размер изображения\n","        '''\n","\n","    # загружаем оригинальное изображение и получаем его формат\n","    img = image.load_img(filename)\n","    width, height = img.size\n","\n","    # загружаем изображение с заданными размерами (416х416)\n","    img = image.load_img(filename, target_size=shape)\n","\n","    # преобразуем в numpy массив\n","    img = image.img_to_array(img)\n","\n","    # нормируем значение пикселей в диапазоне [0, 1]\n","    img = img.astype('float32')\n","    img /= 255.0\n","\n","    # добавляем размерность в начало\n","    img = np.expand_dims(img, 0)\n","\n","    return img, width, height"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6kH7fWHF7huA"},"outputs":[],"source":["def object_detection(model, file_list, labels, class_threshold=0.7, num_images=3):\n","\n","    ''' Функция отрисовки результатов\n","        Args:\n","            model - модель\n","            file_list - списко файлов\n","            labels - названия классов\n","            class_threshold - порог вероятности\n","            num_images - количество изображений\n","\n","        Return:\n","            - img, width, height - размер изображения\n","        '''\n","\n","    WIDTH, HEIGHT = 416, 416\n","\n","    # Параметры испльзовавшиеся в наборе данных, на которых YOLOv3 был натренирован.\n","    anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n","    fnames = np.random.choice(np.array(file_list), num_images)\n","\n","    for fname in fnames:\n","\n","       # загружаем изображение\n","       img, image_w, image_h = load_image_pixels(path+fname, (WIDTH, HEIGHT))\n","\n","       # анализируем фотографию\n","       yhat = model.predict(img)\n","\n","       # задаем пустой лист для рамок\n","       boxes = list()\n","       for i in range(len(yhat)):\n","          # декодируем выход с нейросети\n","          boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, HEIGHT, WIDTH)\n","\n","       # корректируем размеры рамкок соглсно оригинальным размера фотографий\n","       correct_yolo_boxes(boxes, image_h, image_w, HEIGHT, WIDTH)\n","\n","       # suppress non-maximal boxes\n","       do_nms(boxes, 0.5)\n","\n","       # получаем рамки для обнаруженных объектов\n","       v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n","\n","       # Вывод информации о найденных объектах\n","       for i in range(len(v_boxes)):\n","\n","          print(v_labels[i], v_scores[i])\n","\n","       # вывод фотографий с отмеченными на них объектами\n","       draw_boxes(path+fname, v_boxes, v_labels, v_scores)"]},{"cell_type":"markdown","metadata":{"id":"j-KaIAq1OiEa"},"source":["Формируем список названий файлов тестовых картинок."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NymErytj7mz_"},"outputs":[],"source":["test_fnames = []\n","\n","for annot in annot_list[num_train:]: # проходимся по тренировочным аннотациям\n","\n","    fname = annot.split()[0] # извлекаем имя файла с картинкой\n","    test_fnames.append(f'Изобржаения/{fname}') # добавляем в общий список"]},{"cell_type":"markdown","metadata":{"id":"q1dWkhasOkRI"},"source":["Cоздаем модель YOLOv3 для предсказания."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zn-fSVwH7rkB"},"outputs":[],"source":["yolo3 = create_yolov3_model(Input(shape=(size, size, 3)), num_sub_anchors, num_classes)"]},{"cell_type":"markdown","metadata":{"id":"ACZAptWjOrn5"},"source":["Загружаем предобученные веса."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4r-n7npF7uWX"},"outputs":[],"source":["yolo3.load_weights(weights_path)"]},{"cell_type":"markdown","metadata":{"id":"x1mvitqjOwWA"},"source":["Получаем предсказания на 10 первых картинках тестового набора."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yvIPd2TF7yQ6"},"outputs":[],"source":["object_detection(yolo3, test_fnames[:10], classes, class_threshold=0.2, num_images=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3oaoIze0xDq8"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1gHMNNxWNHrdEf-a7iJ1XlikxPJULiGc3","timestamp":1668097795810},{"file_id":"1R8bQw7fyDpXDS6UwE-9p5btSBqvkm6yy","timestamp":1650649835289}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}