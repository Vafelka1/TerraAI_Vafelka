{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"18qVX4QOORiqYod8ftEgI-CBwpOzoBDgK","timestamp":1716033314829},{"file_id":"1-3ztSCtqkrUKBGXR-Efd2eVgDA7krrz7","timestamp":1715278672676}],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyP1xts5GqGlMhnSlPQiM6i3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!unzip -q '/content/drive/MyDrive/Диплом/KaggleOnly.zip' -d '/content'"],"metadata":{"id":"jfZBVWILYSZa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715279164144,"user_tz":-180,"elapsed":155408,"user":{"displayName":"Vafelka","userId":"11276804272897708630"}},"outputId":"bdc394b2-4c89-4627-f2ca-71c736874903"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/preprocessed')\n","print(\"We are currently in the folder of \",os.getcwd())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r6j2S8zLbbbC","executionInfo":{"status":"ok","timestamp":1715279164144,"user_tz":-180,"elapsed":6,"user":{"displayName":"Vafelka","userId":"11276804272897708630"}},"outputId":"f4bab323-acc5-403b-e307-f7cd9b78bf51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["We are currently in the folder of  /content/preprocessed\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","data_list = []\n","for i in range(5):\n","    list = os.listdir(os.path.join(str(i)))\n","    for j in list:\n","        id_code = j.split('.')[0]\n","        diagnosis = i #str(i)\n","        ser = [id_code,diagnosis]\n","        data_list.append(ser)\n","columns = ['id_code','diagnosis']\n","df = pd.DataFrame(data=data_list,columns=columns)"],"metadata":{"id":"LXppbpuKZcmL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df.sort_values(by=['id_code'])\n","df_train = df[:28450]\n","df_valid = df[28450:31964]\n","df_test = df[31964:]\n","print(df_train.shape,df_valid.shape,df_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vvmARlQTafvX","executionInfo":{"status":"ok","timestamp":1715279218376,"user_tz":-180,"elapsed":2,"user":{"displayName":"Vafelka","userId":"11276804272897708630"}},"outputId":"a2435ccd-72ac-450a-873a-f93917941412"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(28450, 2) (3514, 2) (3162, 2)\n"]}]},{"cell_type":"code","source":["os.chdir('/content')\n","print(\"We are currently in the folder of \",os.getcwd())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZoXLomQpe_c","executionInfo":{"status":"ok","timestamp":1715279221534,"user_tz":-180,"elapsed":2,"user":{"displayName":"Vafelka","userId":"11276804272897708630"}},"outputId":"866a8fc6-61d4-46f8-e853-025a5c0aa884"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["We are currently in the folder of  /content\n"]}]},{"cell_type":"code","source":["TRAIN_PATH = '/content/preprocessed/' # Папка для обучающего набора данных\n","NEW_TRAIN_PATH = '/content/Train/'  # Папка для перегона данных\n","# Определение списка имен классов\n","CLASS_LIST = sorted(os.listdir(TRAIN_PATH))\n","# Определение количества классов\n","CLASS_COUNT = len(CLASS_LIST)\n","# Проверка результата\n","print(f'Количество классов: {CLASS_COUNT}, метки классов: {CLASS_LIST}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QO9TmI_WaMES","executionInfo":{"status":"ok","timestamp":1715279224356,"user_tz":-180,"elapsed":2,"user":{"displayName":"Vafelka","userId":"11276804272897708630"}},"outputId":"aa7ffafd-c5ee-4e7f-b3b4-65762c718f18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Количество классов: 5, метки классов: ['0', '1', '2', '3', '4']\n"]}]},{"cell_type":"code","source":["os.mkdir(NEW_TRAIN_PATH)\n","for class_name in CLASS_LIST:                              # Для всех классов по порядку номеров (их меток)\n","    class_path = f'{TRAIN_PATH}{class_name}'              # Формирование полного пути к папке с изображениями класса\n","    new_train_path = f'{NEW_TRAIN_PATH}'                # Полный путь\n","    class_files = os.listdir(class_path)                   # Получение списка имен файлов с изображениями текущего класса\n","    for f in class_files:                                   # Перемещение тестовых файлов в новую папку\n","      os.rename(f'{class_path}/{f}', f'{new_train_path}{f}')\n","      #print(f'{class_path}/{f}-----{new_train_path}{f}')"],"metadata":{"id":"VS_Jh03ZZ6-D"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aY4Z-t0ppHQI"},"outputs":[],"source":["import torch\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","LEARNING_RATE = 3e-5\n","WEIGHT_DECAY = 5e-4\n","BATCH_SIZE = 20\n","NUM_EPOCHS = 100\n","NUM_WORKERS = 6\n","CHECKPOINT_FILE = \"b3_fit_3.pth.tar\"\n","PIN_MEMORY = True\n","SAVE_MODEL = True\n","LOAD_MODEL = True\n","\n","# Data augmentation for images\n","train_transforms = A.Compose(\n","    [\n","        A.Resize(width=628, height=628),\n","        A.HorizontalFlip(p=0.5),\n","        A.VerticalFlip(p=0.5),\n","        A.RandomRotate90(p=0.5),\n","        A.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=(0, 0), p=0.5),\n","        A.GaussianBlur(blur_limit=(3, 7), sigma_limit=0, always_apply=True, p=1),\n","        A.CoarseDropout(max_holes=12, max_height=10, max_width=20, p=0.3),\n","        A.Normalize(\n","            mean=[0.3199, 0.2240, 0.1609],\n","            std=[0.3020, 0.2183, 0.1741],\n","            max_pixel_value=255.0,\n","        ),\n","        ToTensorV2(),\n","    ]\n",")\n","\n","val_transforms = A.Compose(\n","    [\n","        A.Resize(height=512, width=512),\n","        A.GaussianBlur(blur_limit=(3, 7), sigma_limit=0, always_apply=True, p=1),\n","        A.Normalize(\n","            mean=[0.3199, 0.2240, 0.1609],\n","            std=[0.3020, 0.2183, 0.1741],\n","            max_pixel_value=255.0,\n","        ),\n","        ToTensorV2(),\n","    ]\n",")"]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from tqdm import tqdm\n","\n","\n","class DRDataset(Dataset):\n","    def __init__(self, images_folder, path_to_csv, train=True, transform=None):\n","        super().__init__()\n","        self.data = pd.read_csv(path_to_csv)\n","        self.images_folder = images_folder\n","        self.image_files = os.listdir(images_folder)\n","        self.transform = transform\n","        self.train = train\n","\n","    def __len__(self):\n","        return self.data.shape[0] if self.train else len(self.image_files)\n","\n","    def __getitem__(self, index):\n","        if self.train:\n","            image_file, label = self.data.iloc[index]\n","        else:\n","            # if test simply return -1 for label, I do this in order to\n","            # re-use same dataset class for test set submission later on\n","            image_file, label = self.image_files[index], -1\n","            image_file = image_file.replace(\".jpeg\", \"\")\n","\n","        image = np.array(Image.open(os.path.join(self.images_folder, image_file+\".jpeg\")))\n","\n","        if self.transform:\n","            image = self.transform(image=image)[\"image\"]\n","\n","        return image, label, image_file\n"],"metadata":{"id":"vucZ7ljWpRR_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","import warnings\n","import torch.nn.functional as F\n","\n","\n","def make_prediction(model, loader, output_csv=\"submission.csv\"):\n","    preds = []\n","    filenames = []\n","    model.eval()\n","\n","    for x, y, files in tqdm(loader):\n","        x = x.to(DEVICE)\n","        with torch.no_grad():\n","            predictions = model(x)\n","            # Convert MSE floats to integer predictions\n","            predictions[predictions < 0.5] = 0\n","            predictions[(predictions >= 0.5) & (predictions < 1.5)] = 1\n","            predictions[(predictions >= 1.5) & (predictions < 2.5)] = 2\n","            predictions[(predictions >= 2.5) & (predictions < 3.5)] = 3\n","            predictions[(predictions >= 3.5) & (predictions < 10000000)] = 4\n","            predictions = predictions.long().squeeze(1)\n","            preds.append(predictions.cpu().numpy())\n","            filenames += files\n","\n","    df = pd.DataFrame({\"image\": filenames, \"level\": np.concatenate(preds, axis=0)})\n","    df.to_csv(output_csv, index=False)\n","    model.train()\n","    print(\"Done with predictions\")\n","\n","\n","def check_accuracy(loader, model, device=\"cuda\"):\n","    model.eval()\n","    all_preds, all_labels = [], []\n","    num_correct = 0\n","    num_samples = 0\n","\n","    for x, y, filename in tqdm(loader):\n","        x = x.to(device=device)\n","        y = y.to(device=device)\n","\n","        with torch.no_grad():\n","            predictions = model(x)\n","\n","        # Convert MSE floats to integer predictions\n","        predictions[predictions < 0.5] = 0\n","        predictions[(predictions >= 0.5) & (predictions < 1.5)] = 1\n","        predictions[(predictions >= 1.5) & (predictions < 2.5)] = 2\n","        predictions[(predictions >= 2.5) & (predictions < 3.5)] = 3\n","        predictions[(predictions >= 3.5) & (predictions < 100)] = 4\n","        predictions = predictions.long().view(-1)\n","        y = y.view(-1)\n","\n","        num_correct += (predictions == y).sum()\n","        num_samples += predictions.shape[0]\n","\n","        # add to lists\n","        all_preds.append(predictions.detach().cpu().numpy())\n","        all_labels.append(y.detach().cpu().numpy())\n","\n","    print(\n","        f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\"\n","    )\n","    model.train()\n","    return np.concatenate(all_preds, axis=0, dtype=np.int64), np.concatenate(\n","        all_labels, axis=0, dtype=np.int64\n","    )\n","\n","\n","def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n","    print(\"=> Saving checkpoint\")\n","    torch.save(state, filename)\n","\n","\n","def load_checkpoint(checkpoint, model, optimizer, lr):\n","    print(\"=> Loading checkpoint\")\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","    #optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","\n","    # If we don't do this then it will just have learning rate of old checkpoint\n","    # and it will lead to many hours of debugging \\:\n","    for param_group in optimizer.param_groups:\n","        param_group[\"lr\"] = lr\n","\n","\n","def get_csv_for_blend(loader, model, output_csv_file):\n","    warnings.warn(\"Important to have shuffle=False (and to ensure batch size is even size) when running get_csv_for_blend also set val_transforms to train_loader!\")\n","    model.eval()\n","    filename_first = []\n","    filename_second = []\n","    labels_first = []\n","    labels_second = []\n","    all_features = []\n","\n","    for idx, (images, y, image_files) in enumerate(tqdm(loader)):\n","        images = images.to(DEVICE)\n","\n","        with torch.no_grad():\n","            features = F.adaptive_avg_pool2d(\n","                model.extract_features(images), output_size=1\n","            )\n","            features_logits = features.reshape(features.shape[0] // 2, 2, features.shape[1])\n","            preds = model(images).reshape(images.shape[0] // 2, 2, 1)\n","            new_features = (\n","                torch.cat([features_logits, preds], dim=2)\n","                .view(preds.shape[0], -1)\n","                .cpu()\n","                .numpy()\n","            )\n","            all_features.append(new_features)\n","            filename_first += image_files[::2]\n","            filename_second += image_files[1::2]\n","            labels_first.append(y[::2].cpu().numpy())\n","            labels_second.append(y[1::2].cpu().numpy())\n","\n","    all_features = np.concatenate(all_features, axis=0)\n","    df = pd.DataFrame(\n","        data=all_features, columns=[f\"f_{idx}\" for idx in range(all_features.shape[1])]\n","    )\n","    df[\"label_first\"] = np.concatenate(labels_first, axis=0)\n","    df[\"label_second\"] = np.concatenate(labels_second, axis=0)\n","    df[\"file_first\"] = filename_first\n","    df[\"file_second\"] = filename_second\n","    df.to_csv(output_csv_file, index=False)\n","    model.train()"],"metadata":{"id":"sAqed-eSpdhr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!pip install efficientnet_pytorch"],"metadata":{"id":"dKjNCp5Emodf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715279318580,"user_tz":-180,"elapsed":564,"user":{"displayName":"Vafelka","userId":"11276804272897708630"}},"outputId":"8074ec17-26e1-4ecc-b22d-92ab7c94e68a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully installed efficientnet_pytorch-0.7.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"]}]},{"cell_type":"code","source":["import torch\n","from torch import nn, optim\n","import os\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from sklearn.metrics import cohen_kappa_score\n","from efficientnet_pytorch import EfficientNet\n","from torchvision.utils import save_image\n","\n","\n","def train_one_epoch(loader, model, optimizer, loss_fn, scaler, device,save_ex=False):\n","    losses = []\n","    loop = tqdm(loader)\n","    for batch_idx, (data, targets, _) in enumerate(loop):\n","        # save examples and make sure they look ok with the data augmentation,\n","        # tip is to first set mean=[0,0,0], std=[1,1,1] so they look \"normal\"\n","        #if save_ex: save_image(data, f\"hi_{batch_idx}.png\")\n","\n","        data = data.to(device=device)\n","        targets = targets.to(device=device)\n","\n","        # forward\n","        with torch.cuda.amp.autocast():\n","            scores = model(data)\n","            loss = loss_fn(scores, targets.unsqueeze(1).float())\n","\n","        losses.append(loss.item())\n","\n","        # backward\n","        optimizer.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        loop.set_postfix(loss=loss.item())\n","\n","    print(f\"Loss average over epoch: {sum(losses)/len(losses)}\")\n","\n","\n","def fit():\n","    train_ds = DRDataset(\n","        images_folder=\"Train\",\n","        path_to_csv=\"trainLabels.csv\",\n","        transform=train_transforms,\n","    )\n","    val_ds = DRDataset(\n","        images_folder=\"Train\",\n","        path_to_csv=\"valLabels.csv\",\n","        transform=val_transforms,\n","    )\n","    test_ds = DRDataset(\n","        images_folder=\"Train\",\n","        path_to_csv=\"testLabels.csv\",\n","        transform=val_transforms,\n","        train=False,\n","    )\n","    test_loader = DataLoader(\n","        test_ds, batch_size=BATCH_SIZE, num_workers=6, shuffle=False\n","    )\n","    train_loader = DataLoader(\n","        train_ds,\n","        batch_size=BATCH_SIZE,\n","        num_workers=NUM_WORKERS,\n","        pin_memory=PIN_MEMORY,\n","        shuffle=False,\n","    )\n","    val_loader = DataLoader(\n","        val_ds,\n","        batch_size=BATCH_SIZE,\n","        num_workers=2,\n","        pin_memory=PIN_MEMORY,\n","        shuffle=False,\n","    )\n","    loss_fn = nn.MSELoss()\n","\n","    model = EfficientNet.from_pretrained(\"efficientnet-b3\")\n","    #model._fc = nn.Flatten()\n","    model._fc = nn.Linear(1536, 1)\n","    model = model.to(DEVICE)\n","    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","    scaler = torch.cuda.amp.GradScaler()\n","\n","    if LOAD_MODEL and CHECKPOINT_FILE in os.listdir():\n","        load_checkpoint(torch.load(CHECKPOINT_FILE), model, optimizer, LEARNING_RATE)\n","\n","    # Run after training is done and you've achieved good result\n","    # on validation set, then run train_blend.py file to use information\n","    # about both eyes concatenated\n","    #get_csv_for_blend(val_loader, model, \"../train/val_blend.csv\")\n","    #get_csv_for_blend(train_loader, model, \"../train/train_blend.csv\")\n","    #get_csv_for_blend(test_loader, model, \"../train/test_blend.csv\")\n","    #make_prediction(model, test_loader, \"submission_.csv\")\n","    #import sys\n","    #sys.exit()\n","    #make_prediction(model, test_loader)\n","\n","    for epoch in range(NUM_EPOCHS):\n","        train_one_epoch(train_loader, model, optimizer, loss_fn, scaler, DEVICE)\n","\n","        # get on validation\n","        preds, labels = check_accuracy(val_loader, model, DEVICE)\n","        print(f\"QuadraticWeightedKappa (Validation): {cohen_kappa_score(labels, preds, weights='quadratic')}\")\n","\n","        # get on train\n","        #preds, labels = check_accuracy(train_loader, model, DEVICE)\n","        #print(f\"QuadraticWeightedKappa (Training): {cohen_kappa_score(labels, preds, weights='quadratic')}\")\n","\n","        if SAVE_MODEL:\n","            checkpoint = {\n","                \"state_dict\": model.state_dict(),\n","                \"optimizer\": optimizer.state_dict(),\n","            }\n","            save_checkpoint(checkpoint, filename=f\"b3_{epoch}.pth.tar\")\n"],"metadata":{"id":"d86ZGZ6Opi5e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#os.environ['PYTORCH_CUDA_ALLOC_CONF']='expandable_segments:True'\n","import torch\n","torch.cuda.empty_cache()"],"metadata":{"id":"U-wJ-nTYthd4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fit()"],"metadata":{"id":"UApu3zvrXVMX","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"57313cc6-8e03-40d5-bce5-ae3acae2261b","executionInfo":{"status":"error","timestamp":1715284112428,"user_tz":-180,"elapsed":4759660,"user":{"displayName":"Vafelka","userId":"11276804272897708630"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b3-5fb5a3c3.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b3-5fb5a3c3.pth\n","100%|██████████| 47.1M/47.1M [00:00<00:00, 214MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loaded pretrained weights for efficientnet-b3\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1423 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","100%|██████████| 1423/1423 [19:00<00:00,  1.25it/s, loss=0.245]\n"]},{"output_type":"stream","name":"stdout","text":["Loss average over epoch: 0.5032284061201258\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 176/176 [00:50<00:00,  3.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Got 2661 / 3514 with accuracy 75.73\n","QuadraticWeightedKappa (Validation): 0.5076748168650487\n","=> Saving checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1423 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","100%|██████████| 1423/1423 [18:56<00:00,  1.25it/s, loss=0.374]\n"]},{"output_type":"stream","name":"stdout","text":["Loss average over epoch: 0.36979998007039744\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 176/176 [00:49<00:00,  3.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Got 2753 / 3514 with accuracy 78.34\n","QuadraticWeightedKappa (Validation): 0.6212069865614287\n","=> Saving checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1423 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","100%|██████████| 1423/1423 [18:54<00:00,  1.25it/s, loss=0.375]\n"]},{"output_type":"stream","name":"stdout","text":["Loss average over epoch: 0.3254929228711321\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 176/176 [00:49<00:00,  3.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Got 2788 / 3514 with accuracy 79.34\n","QuadraticWeightedKappa (Validation): 0.6317680028121216\n","=> Saving checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1423 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","100%|██████████| 1423/1423 [18:54<00:00,  1.25it/s, loss=0.215]\n"]},{"output_type":"stream","name":"stdout","text":["Loss average over epoch: 0.3007717797636085\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 176/176 [00:49<00:00,  3.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Got 2789 / 3514 with accuracy 79.37\n","QuadraticWeightedKappa (Validation): 0.6275411336084755\n","=> Saving checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1423 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","  1%|          | 11/1423 [00:10<22:01,  1.07it/s, loss=0.538]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-2e8ead0159f0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-13-313c036c5ce4>\u001b[0m in \u001b[0;36mfit\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# get on validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-313c036c5ce4>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(loader, model, optimizer, loss_fn, scaler, device, save_ex)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import shutil\n","shutil.copy('/content/b3_4.pth.tar', '/content/drive/MyDrive/Диплом/Models/628acc79kap62.pth.tar')"],"metadata":{"id":"_QDyhTQjU0mP"},"execution_count":null,"outputs":[]}]}