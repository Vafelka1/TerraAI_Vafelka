{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"18qVX4QOORiqYod8ftEgI-CBwpOzoBDgK","timestamp":1715330961993},{"file_id":"1-3ztSCtqkrUKBGXR-Efd2eVgDA7krrz7","timestamp":1715278672676}],"gpuType":"T4","authorship_tag":"ABX9TyODQVu/R6Qru/9NyTL9TAft"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import gdown\n","url = 'https://drive.google.com/drive/folders/1QoCcwlphHKGZMLl_s7wrRjc36_MkCtj5?usp=sharing'\n","gdown.download_folder(url, quiet=True)\n","!unzip -q '/content/Data/KaggleOnly.zip' -d '/content'\n","\n","import shutil\n","shutil.copy('/content/Data/trainLabels.csv', '/content/trainLabels.csv')\n","shutil.copy('/content/Data/valLabels.csv', '/content/valLabels.csv')\n","shutil.copy('/content/Data/testLabels.csv', '/content/testLabels.csv')"],"metadata":{"id":"QF96FeqfRDLu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","TRAIN_PATH = '/content/preprocessed/' # Папка для обучающего набора данных\n","NEW_TRAIN_PATH = '/content/Train/'  # Папка для перегона данных\n","# Определение списка имен классов\n","CLASS_LIST = sorted(os.listdir(TRAIN_PATH))\n","# Определение количества классов\n","CLASS_COUNT = len(CLASS_LIST)\n","# Проверка результата\n","print(f'Количество классов: {CLASS_COUNT}, метки классов: {CLASS_LIST}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QO9TmI_WaMES","executionInfo":{"status":"ok","timestamp":1715331958177,"user_tz":-180,"elapsed":2,"user":{"displayName":"Vafelka","userId":"11276804272897708630"}},"outputId":"9d00b9e9-afb9-4a28-8f76-00d2979070d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Количество классов: 5, метки классов: ['0', '1', '2', '3', '4']\n"]}]},{"cell_type":"code","source":["os.mkdir(NEW_TRAIN_PATH)\n","for class_name in CLASS_LIST:                              # Для всех классов по порядку номеров (их меток)\n","    class_path = f'{TRAIN_PATH}{class_name}'              # Формирование полного пути к папке с изображениями класса\n","    new_train_path = f'{NEW_TRAIN_PATH}'                # Полный путь\n","    class_files = os.listdir(class_path)                   # Получение списка имен файлов с изображениями текущего класса\n","    for f in class_files:                                   # Перемещение тестовых файлов в новую папку\n","      os.rename(f'{class_path}/{f}', f'{new_train_path}{f}')\n","      #print(f'{class_path}/{f}-----{new_train_path}{f}')"],"metadata":{"id":"VS_Jh03ZZ6-D"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aY4Z-t0ppHQI"},"outputs":[],"source":["import torch\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","LEARNING_RATE = 3e-5\n","WEIGHT_DECAY = 5e-4\n","BATCH_SIZE = 24\n","NUM_EPOCHS = 5\n","NUM_WORKERS = 6\n","CHECKPOINT_FILE = \"b6_1.pth.tar\"\n","PIN_MEMORY = True\n","SAVE_MODEL = True\n","LOAD_MODEL = True\n","\n","# Data augmentation for images\n","train_transforms = A.Compose(\n","    [\n","        A.Resize(width=428, height=428),\n","        A.HorizontalFlip(p=0.5),\n","        A.VerticalFlip(p=0.5),\n","        A.RandomRotate90(p=0.5),\n","        A.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=(0, 0), p=0.5),\n","        A.GaussianBlur(blur_limit=(3, 7), sigma_limit=0, always_apply=True, p=1),\n","        A.CoarseDropout(max_holes=12, max_height=10, max_width=20, p=0.3),\n","        A.Normalize(\n","            mean=[0.3199, 0.2240, 0.1609],\n","            std=[0.3020, 0.2183, 0.1741],\n","            max_pixel_value=255.0,\n","        ),\n","        ToTensorV2(),\n","    ]\n",")\n","\n","val_transforms = A.Compose(\n","    [\n","        A.Resize(height=428, width=428),\n","        A.GaussianBlur(blur_limit=(3, 7), sigma_limit=0, always_apply=True, p=1),\n","        A.Normalize(\n","            mean=[0.3199, 0.2240, 0.1609],\n","            std=[0.3020, 0.2183, 0.1741],\n","            max_pixel_value=255.0,\n","        ),\n","        ToTensorV2(),\n","    ]\n",")"]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from tqdm import tqdm\n","\n","\n","class DRDataset(Dataset):\n","    def __init__(self, images_folder, path_to_csv, train=True, transform=None):\n","        super().__init__()\n","        self.data = pd.read_csv(path_to_csv)\n","        self.images_folder = images_folder\n","        self.image_files = os.listdir(images_folder)\n","        self.transform = transform\n","        self.train = train\n","\n","    def __len__(self):\n","        return self.data.shape[0] if self.train else len(self.image_files)\n","\n","    def __getitem__(self, index):\n","        if self.train:\n","            image_file, label = self.data.iloc[index]\n","        else:\n","            # if test simply return -1 for label, I do this in order to\n","            # re-use same dataset class for test set submission later on\n","            image_file, label = self.image_files[index], -1\n","            image_file = image_file.replace(\".jpeg\", \"\")\n","\n","        image = np.array(Image.open(os.path.join(self.images_folder, image_file+\".jpeg\")))\n","\n","        if self.transform:\n","            image = self.transform(image=image)[\"image\"]\n","\n","        return image, label, image_file\n"],"metadata":{"id":"vucZ7ljWpRR_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","import warnings\n","import torch.nn.functional as F\n","\n","\n","def make_prediction(model, loader, output_csv=\"submission.csv\"):\n","    preds = []\n","    filenames = []\n","    model.eval()\n","\n","    for x, y, files in tqdm(loader):\n","        x = x.to(DEVICE)\n","        with torch.no_grad():\n","            predictions = model(x)\n","            # Convert MSE floats to integer predictions\n","            predictions[predictions < 0.5] = 0\n","            predictions[(predictions >= 0.5) & (predictions < 1.5)] = 1\n","            predictions[(predictions >= 1.5) & (predictions < 2.5)] = 2\n","            predictions[(predictions >= 2.5) & (predictions < 3.5)] = 3\n","            predictions[(predictions >= 3.5) & (predictions < 10000000)] = 4\n","            predictions = predictions.long().squeeze(1)\n","            preds.append(predictions.cpu().numpy())\n","            filenames += files\n","\n","    df = pd.DataFrame({\"image\": filenames, \"level\": np.concatenate(preds, axis=0)})\n","    df.to_csv(output_csv, index=False)\n","    model.train()\n","    print(\"Done with predictions\")\n","\n","\n","def check_accuracy(loader, model, device=\"cuda\"):\n","    model.eval()\n","    all_preds, all_labels = [], []\n","    num_correct = 0\n","    num_samples = 0\n","\n","    for x, y, filename in tqdm(loader):\n","        x = x.to(device=device)\n","        y = y.to(device=device)\n","\n","        with torch.no_grad():\n","            predictions = model(x)\n","\n","        # Convert MSE floats to integer predictions\n","        predictions[predictions < 0.5] = 0\n","        predictions[(predictions >= 0.5) & (predictions < 1.5)] = 1\n","        predictions[(predictions >= 1.5) & (predictions < 2.5)] = 2\n","        predictions[(predictions >= 2.5) & (predictions < 3.5)] = 3\n","        predictions[(predictions >= 3.5) & (predictions < 100)] = 4\n","        predictions = predictions.long().view(-1)\n","        y = y.view(-1)\n","\n","        num_correct += (predictions == y).sum()\n","        num_samples += predictions.shape[0]\n","\n","        # add to lists\n","        all_preds.append(predictions.detach().cpu().numpy())\n","        all_labels.append(y.detach().cpu().numpy())\n","\n","    print(\n","        f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\"\n","    )\n","    model.train()\n","    return np.concatenate(all_preds, axis=0, dtype=np.int64), np.concatenate(\n","        all_labels, axis=0, dtype=np.int64\n","    )\n","\n","\n","def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n","    print(\"=> Saving checkpoint\")\n","    torch.save(state, filename)\n","\n","\n","def load_checkpoint(checkpoint, model, optimizer, lr):\n","    print(\"=> Loading checkpoint\")\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","    #optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","\n","    # If we don't do this then it will just have learning rate of old checkpoint\n","    # and it will lead to many hours of debugging \\:\n","    for param_group in optimizer.param_groups:\n","        param_group[\"lr\"] = lr\n","\n","\n","def get_csv_for_blend(loader, model, output_csv_file):\n","    warnings.warn(\"Important to have shuffle=False (and to ensure batch size is even size) when running get_csv_for_blend also set val_transforms to train_loader!\")\n","    model.eval()\n","    filename_first = []\n","    filename_second = []\n","    labels_first = []\n","    labels_second = []\n","    all_features = []\n","\n","    for idx, (images, y, image_files) in enumerate(tqdm(loader)):\n","        images = images.to(DEVICE)\n","\n","        with torch.no_grad():\n","            features = F.adaptive_avg_pool2d(\n","                model.extract_features(images), output_size=1\n","            )\n","            features_logits = features.reshape(features.shape[0] // 2, 2, features.shape[1])\n","            preds = model(images).reshape(images.shape[0] // 2, 2, 1)\n","            new_features = (\n","                torch.cat([features_logits, preds], dim=2)\n","                .view(preds.shape[0], -1)\n","                .cpu()\n","                .numpy()\n","            )\n","            all_features.append(new_features)\n","            filename_first += image_files[::2]\n","            filename_second += image_files[1::2]\n","            labels_first.append(y[::2].cpu().numpy())\n","            labels_second.append(y[1::2].cpu().numpy())\n","\n","    all_features = np.concatenate(all_features, axis=0)\n","    df = pd.DataFrame(\n","        data=all_features, columns=[f\"f_{idx}\" for idx in range(all_features.shape[1])]\n","    )\n","    df[\"label_first\"] = np.concatenate(labels_first, axis=0)\n","    df[\"label_second\"] = np.concatenate(labels_second, axis=0)\n","    df[\"file_first\"] = filename_first\n","    df[\"file_second\"] = filename_second\n","    df.to_csv(output_csv_file, index=False)\n","    model.train()"],"metadata":{"id":"sAqed-eSpdhr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install efficientnet_pytorch"],"metadata":{"id":"dKjNCp5Emodf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from efficientnet_pytorch import EfficientNet\n","model = EfficientNet.from_pretrained(\"efficientnet-b6\")\n","print(model)"],"metadata":{"id":"shdstzzjtEoN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch import nn, optim\n","import os\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from sklearn.metrics import cohen_kappa_score\n","from efficientnet_pytorch import EfficientNet\n","from torchvision.utils import save_image\n","\n","\n","def train_one_epoch(loader, model, optimizer, loss_fn, scaler, device,save_ex=False):\n","    losses = []\n","    loop = tqdm(loader)\n","    for batch_idx, (data, targets, _) in enumerate(loop):\n","        # save examples and make sure they look ok with the data augmentation,\n","        # tip is to first set mean=[0,0,0], std=[1,1,1] so they look \"normal\"\n","        #if save_ex: save_image(data, f\"hi_{batch_idx}.png\")\n","\n","        data = data.to(device=device)\n","        targets = targets.to(device=device)\n","\n","        # forward\n","        with torch.cuda.amp.autocast():\n","            scores = model(data)\n","            loss = loss_fn(scores, targets.unsqueeze(1).float())\n","\n","        losses.append(loss.item())\n","\n","        # backward\n","        optimizer.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        loop.set_postfix(loss=loss.item())\n","\n","    print(f\"Loss average over epoch: {sum(losses)/len(losses)}\")\n","\n","\n","def fit():\n","    train_ds = DRDataset(\n","        images_folder=\"Train\",\n","        path_to_csv=\"trainLabels.csv\",\n","        transform=train_transforms,\n","    )\n","    val_ds = DRDataset(\n","        images_folder=\"Train\",\n","        path_to_csv=\"valLabels.csv\",\n","        transform=val_transforms,\n","    )\n","    test_ds = DRDataset(\n","        images_folder=\"Train\",\n","        path_to_csv=\"testLabels.csv\",\n","        transform=val_transforms,\n","        train=False,\n","    )\n","    test_loader = DataLoader(\n","        test_ds, batch_size=BATCH_SIZE, num_workers=6, shuffle=False\n","    )\n","    train_loader = DataLoader(\n","        train_ds,\n","        batch_size=BATCH_SIZE,\n","        num_workers=NUM_WORKERS,\n","        pin_memory=PIN_MEMORY,\n","        shuffle=False,\n","    )\n","    val_loader = DataLoader(\n","        val_ds,\n","        batch_size=BATCH_SIZE,\n","        num_workers=2,\n","        pin_memory=PIN_MEMORY,\n","        shuffle=False,\n","    )\n","    loss_fn = nn.MSELoss()\n","\n","    model = EfficientNet.from_pretrained(\"efficientnet-b6\")\n","    #model._fc = nn.Flatten()\n","    model._fc = nn.Linear(2304, 1)\n","    model = model.to(DEVICE)\n","    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","    scaler = torch.cuda.amp.GradScaler()\n","\n","    if LOAD_MODEL and CHECKPOINT_FILE in os.listdir():\n","        load_checkpoint(torch.load(CHECKPOINT_FILE), model, optimizer, LEARNING_RATE)\n","\n","    # Run after training is done and you've achieved good result\n","    # on validation set, then run train_blend.py file to use information\n","    # about both eyes concatenated\n","    #get_csv_for_blend(val_loader, model, \"../train/val_blend.csv\")\n","    #get_csv_for_blend(train_loader, model, \"../train/train_blend.csv\")\n","    #get_csv_for_blend(test_loader, model, \"../train/test_blend.csv\")\n","    #make_prediction(model, test_loader, \"submission_.csv\")\n","    #import sys\n","    #sys.exit()\n","    #make_prediction(model, test_loader)\n","\n","    for epoch in range(NUM_EPOCHS):\n","        train_one_epoch(train_loader, model, optimizer, loss_fn, scaler, DEVICE)\n","\n","        # get on validation\n","        preds, labels = check_accuracy(val_loader, model, DEVICE)\n","        print(f\"QuadraticWeightedKappa (Validation): {cohen_kappa_score(labels, preds, weights='quadratic')}\")\n","\n","        # get on train\n","        #preds, labels = check_accuracy(train_loader, model, DEVICE)\n","        #print(f\"QuadraticWeightedKappa (Training): {cohen_kappa_score(labels, preds, weights='quadratic')}\")\n","\n","        if SAVE_MODEL:\n","            checkpoint = {\n","                \"state_dict\": model.state_dict(),\n","                \"optimizer\": optimizer.state_dict(),\n","            }\n","            save_checkpoint(checkpoint, filename=f\"b5_ft_{epoch}.pth.tar\")\n"],"metadata":{"id":"d86ZGZ6Opi5e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#os.environ['PYTORCH_CUDA_ALLOC_CONF']='expandable_segments:True'\n","import torch\n","torch.cuda.empty_cache()"],"metadata":{"id":"U-wJ-nTYthd4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fit()"],"metadata":{"id":"UApu3zvrXVMX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d3a49946-f521-4929-845c-dd640cef267c","executionInfo":{"status":"ok","timestamp":1715350761527,"user_tz":-180,"elapsed":6115309,"user":{"displayName":"Vafelka","userId":"11276804272897708630"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded pretrained weights for efficientnet-b6\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1186 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","100%|██████████| 1186/1186 [19:02<00:00,  1.04it/s, loss=0.549]\n"]},{"output_type":"stream","name":"stdout","text":["Loss average over epoch: 0.656202839709454\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 147/147 [01:21<00:00,  1.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Got 2560 / 3514 with accuracy 72.85\n","QuadraticWeightedKappa (Validation): 0.6109152974660994\n","=> Saving checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1186 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","100%|██████████| 1186/1186 [19:00<00:00,  1.04it/s, loss=0.451]\n"]},{"output_type":"stream","name":"stdout","text":["Loss average over epoch: 0.466991749885814\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 147/147 [01:20<00:00,  1.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Got 2585 / 3514 with accuracy 73.56\n","QuadraticWeightedKappa (Validation): 0.6846676631592102\n","=> Saving checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1186 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","100%|██████████| 1186/1186 [19:00<00:00,  1.04it/s, loss=0.39]\n"]},{"output_type":"stream","name":"stdout","text":["Loss average over epoch: 0.41038010858037016\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 147/147 [01:20<00:00,  1.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Got 2634 / 3514 with accuracy 74.96\n","QuadraticWeightedKappa (Validation): 0.7070422710611559\n","=> Saving checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1186 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","100%|██████████| 1186/1186 [19:00<00:00,  1.04it/s, loss=0.382]\n"]},{"output_type":"stream","name":"stdout","text":["Loss average over epoch: 0.3714456064548048\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 147/147 [01:20<00:00,  1.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Got 2719 / 3514 with accuracy 77.38\n","QuadraticWeightedKappa (Validation): 0.7350545711260148\n","=> Saving checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1186 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","100%|██████████| 1186/1186 [19:00<00:00,  1.04it/s, loss=0.387]\n"]},{"output_type":"stream","name":"stdout","text":["Loss average over epoch: 0.33094792217518787\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 147/147 [01:20<00:00,  1.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Got 2728 / 3514 with accuracy 77.63\n","QuadraticWeightedKappa (Validation): 0.7380122040293396\n","=> Saving checkpoint\n"]}]},{"cell_type":"code","source":["train_ds1 = DRDataset(\n","        images_folder=\"Train\",\n","        path_to_csv=\"trainLabels.csv\",\n","        transform=train_transforms,\n","    )\n","train_loader = DataLoader(\n","        train_ds1,\n","        batch_size=BATCH_SIZE,\n","        num_workers=NUM_WORKERS,\n","        pin_memory=PIN_MEMORY,\n","        shuffle=False,\n","    )"],"metadata":{"id":"auVfEQ9uRqt2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs, classes, _ = next(iter(train_loader))\n","save_image(inputs, f\"hi_0.png\")"],"metadata":{"id":"-M4SdOb0Ri7g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715350764759,"user_tz":-180,"elapsed":2686,"user":{"displayName":"Vafelka","userId":"11276804272897708630"}},"outputId":"80b28f55-813c-4837-e9b4-ea051c4bc705"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]}]},{"cell_type":"code","source":["from PIL import Image\n","Image.open(\"hi_0.png\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":498,"output_embedded_package_id":"1uhZkGmMWTEW8w1T5NWEGu1fGgYjV5ccy"},"id":"6IEgCQBMTeFe","executionInfo":{"status":"ok","timestamp":1715350782951,"user_tz":-180,"elapsed":18194,"user":{"displayName":"Vafelka","userId":"11276804272897708630"}},"outputId":"ae42bffa-31c4-4318-9678-cb48da5329ef"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["CHECKPOINT_FILE = \"b5_ft_4.pth.tar\"\n","LEARNING_RATE = 5e-6\n","NUM_EPOCHS = 3\n","fit()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"72w2NOyjWpBw","executionInfo":{"status":"ok","timestamp":1715355792220,"user_tz":-180,"elapsed":3674694,"user":{"displayName":"Vafelka","userId":"11276804272897708630"}},"outputId":"c22481fd-1b21-4110-881d-d8d15786516f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded pretrained weights for efficientnet-b6\n","=> Loading checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1186 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","100%|██████████| 1186/1186 [19:03<00:00,  1.04it/s, loss=0.231]\n"]},{"output_type":"stream","name":"stdout","text":["Loss average over epoch: 0.28493257172870595\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 147/147 [01:21<00:00,  1.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Got 2713 / 3514 with accuracy 77.21\n","QuadraticWeightedKappa (Validation): 0.7599195944857692\n","=> Saving checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1186 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","100%|██████████| 1186/1186 [19:00<00:00,  1.04it/s, loss=0.229]\n"]},{"output_type":"stream","name":"stdout","text":["Loss average over epoch: 0.2736490951665688\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 147/147 [01:20<00:00,  1.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Got 2724 / 3514 with accuracy 77.52\n","QuadraticWeightedKappa (Validation): 0.7613766291820763\n","=> Saving checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1186 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","100%|██████████| 1186/1186 [19:01<00:00,  1.04it/s, loss=0.133]\n"]},{"output_type":"stream","name":"stdout","text":["Loss average over epoch: 0.263389818411176\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 147/147 [01:20<00:00,  1.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Got 2724 / 3514 with accuracy 77.52\n","QuadraticWeightedKappa (Validation): 0.7575950928014021\n","=> Saving checkpoint\n"]}]},{"cell_type":"code","source":["import shutil\n","shutil.copy('/content/b5_ft_1.pth.tar', '/content/drive/MyDrive/Диплом/Models/EffNetB6_428acc77kap76.pth.tar')"],"metadata":{"id":"_QDyhTQjU0mP","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1715355933103,"user_tz":-180,"elapsed":3693,"user":{"displayName":"Vafelka","userId":"11276804272897708630"}},"outputId":"70050911-2342-4850-9d3d-b32bcab694b6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Диплом/Models/EffNetB5_428acc77kap76.pth.tar'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":[],"metadata":{"id":"-8DRlmK7ehuH"},"execution_count":null,"outputs":[]}]}